{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - featrue extraction: feature 몇개만 가져와서 Dense 붙이는 방법.\n",
    " - fine tuning: 아예 일부 피처맵 자체를 또 학습 시키는 것.\n",
    " \n",
    "기계학습에 사용될 각각의 데이터를 feature라고 한다.\n",
    "\n",
    "### 정형 vs 비정형 데이터 차이\n",
    "정형데이터는 feature들 간의 순서를 바꿔도 상관없다. 하지만 비정형 데이터는 feature들 간의 순서를 바꾸면 문제가 생긴다.\n",
    "\n",
    "### 데이터가 작을 때 트랜스퍼 러닝을 쓰면?\n",
    "\n",
    "오퍼피팅을 막아버릴 수 있다. 모델 새로 만드는 것보다 이렇게 해버리는게, 훨씬 좋다.\n",
    "\n",
    "\n",
    "### pre-trained learning은 transfer learning인가?\n",
    "\n",
    "엄밀히 말하면 아니다. 그냥 남의 것 가져다 쓰는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with TensorFlow Hub\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\n",
    "\n",
    " - url에서 classification이 붙어있으면, Dense가 붙어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications in keras\n",
    "\n",
    "https://keras.io/applications/\n",
    "\n",
    "RESNET은 이미 인간의 능력을 뛰어 넘었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg = VGG16(include_top = False, \n",
    "            weights = 'imagenet') # top은 마지막 레이어를 말함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - include_top에 따라서 전략이 달라진다. 붙이면 pre-trained이다.\n",
    " \n",
    "레이어 가져오는 방법\n",
    " - 엔덱스로 가져오는 방법\n",
    " - name으로 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_conv1 = vgg.get_layer('block1_conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_3:0' shape=(None, None, None, 3) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_conv1.input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필터 이미지 확인하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, bias = block_conv1.get_weights() \n",
    "# 이렇게 필터 확인한다.\n",
    "# 이 필터는 학습될 때마다 바뀌지 않는다. 고정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b004f09cc8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "filters[0,...,0].shape\n",
    "plt.imshow(filters[...,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features with VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 파인튜닝은 weight 바꾸는 것!\n",
    " - feature extracton은 덴스 붙이는 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "img_path = './elepant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x200347f6688>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x.reshape(224, 224, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe0dbef908>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features.shape\n",
    "# plt.figure(figsize = (20, 10))\n",
    "plt.imshow(features[0][...,11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from an arbitrary intermediate layer with VGG19\n",
    "\n",
    "꼼수를 써서 특정 레이어를 통과한 후 모양을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input,\n",
    "              outputs = base_model.get_layer('block4_conv4').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './elepant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1739c93efc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN/klEQVR4nO3db6xUdX7H8c8HBRIBA4hSBJUVTagoAiGkibih2SjiA3UfbLM+aGi6yj5wk924D2qsyZo0NaZpd7sPmibQNcs2WzcmK5X4ZyMxJlYT0KtBvBQFNNRFEFYleleFy59vH9yhveI9Zy4zZ84Z+L5fyc3MnO+cOd9M+HDOnN/M+TkiBOD8N6HpBgDUg7ADSRB2IAnCDiRB2IEkLqxzY7Y59Y8Upk+fXlpfsGBBYW3Pnj0db/fLL7/U8PCwx6p1FXbbt0n6uaQLJP1bRDzazesB54tVq1aV1jdt2lRYW716dcfb3bp1a2Gt48N42xdI+hdJayRdJ+lu29d1+noAequbz+wrJO2NiPciYljSbyTdWU1bAKrWTdjnSvr9qMf7W8u+wvY62wO2B7rYFoAudfOZfayTAF87ARcR6yWtlzhBBzSpmz37fklXjHo8T9KB7toB0CvdhP01Sdfa/obtSZK+K2lzNW0BqJq7+dWb7dsl/bNGht4ei4i/b/N8DuMBSbfcckthbcuWLV29dkRUP84eEc9Kerab1wBQD74uCyRB2IEkCDuQBGEHkiDsQBKEHUiiq3H2s94Y4+xAzxWNs7NnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJFHrlM1TpkzRDTfcUFgvm4ESQHfYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAErWOs1911VXasGFDYf2RRx4pXf+ZZ54prB09erR03SlTppTWjxw5UlpftGhRYW3q1Kml627btq20jv6zcOHC0vrSpUtL66+88kpp/eKLLy6sDQ4Olq7bqa7CbnufpCFJJyWdiIjlVTQFoHpV7Nn/PCI+quB1APQQn9mBJLoNe0h63vbrtteN9QTb62wP2B5o97kYQO90G/abImKZpDWS7rP9zTOfEBHrI2J5RCyfMWNGl5sD0Kmuwh4RB1q3hyVtkrSiiqYAVK/jsNueYnva6fuSbpXUmzEDAF3r5mz8bEmbbJ9+nf+IiN+1W+nkyZMd1STps88+O7sORxkeHu54XUnauXNnV+vj3PL222+X1oeGhkrrH3zwQWl92bJlZ91TtzoOe0S8J+nGCnsB0EMMvQFJEHYgCcIOJEHYgSQIO5CEI6K2jU2bNi2WLFlSWH/55Zdr6wU4X0WEx1rOnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkqh1nN12fRsDGtTuqkyXX355Ya3dz6nnz59fWDtw4ICOHTvGODuQGWEHkiDsQBKEHUiCsANJEHYgCcIOJFHrlM3A+WLu3Lml9Xvuuae0/vnnnxfW2o2zL168uLBWNsUae3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdqAD7aZkHhgYKK0vXbq0420vWLCgsLZ169bCWts9u+3HbB+2PThq2UzbW2zvad2W/1IfQOPGcxj/S0m3nbHsAUkvRMS1kl5oPQbQx9qGPSJekvTJGYvvlLSxdX+jpLsq7gtAxTr9zD47Ig5KUkQctH1Z0RNtr5O0rsPtAKhIz0/QRcR6SeslLjgJNKnTobdDtudIUuv2cHUtAeiFTsO+WdLa1v21kp6qph0AvdL2uvG2H5e0StIsSYck/UTSf0p6QtKVkt6X9J2IOPMk3tdMmDAhJk2aVFg/duzYePsGzmkXXXRRYe2LL74oXfepp4r3rffff7/27t075nXj235mj4i7C0rfarcugP7B12WBJAg7kARhB5Ig7EAShB1IotafuE6ePFnXXHNNYX1wcLCw1s/WrFlTWt+1a1dpfd++fRV2g3NBu+G1MpddVvjtdE2cOLGwxp4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KodZx94sSJuvTSSwvrV155Zen677//ftUtVeK5555rugUk8uGHHxbWjh8/Xlhjzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSdQ6zj40NKQXX3yxzk0C550nnniisHbkyJHCGnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7ZTNlW7Mrm9jQFIRMeaUzW337LYfs33Y9uCoZQ/b/sD29tbf7VU2C6B64zmM/6Wk28ZY/rOIWNL6e7batgBUrW3YI+IlSZ/U0AuAHurmBN0PbO9oHebPKHqS7XW2B2wPdLEtAF0a1wk62/MlPR0R17cez5b0kaSQ9HeS5kTEX4/jdThBB/RYxyfoCl7sUEScjIhTkjZIWtFNcwB6r6Ow254z6uG3JZ2bcy0DibT9PbvtxyWtkjTL9n5JP5G0yvYSjRzG75P0/R72CKACfKkGOM9U+pkdwLmHsANJEHYgCcIOJEHYgSRqvZS0JNljniiUJNU5MgBkw54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KodZx98uTJmjdvXmH93XffrbEbVGHChPL9xalTp2rq5Nwyffr0wtqsWbNK1509e3Zhbfv27YU19uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARXl0Wp1atXl9Y//vjj0vrAQHOzfi1atKiwdvz48dJ1d+/eXXU7X7FkyZLC2uBg+TQMJ06cKK1zdVkgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdpQq+320JD300EOl9aeffrrKds7Khg0bCmv33ntvjZ3Uq+NxdttX2H7R9i7bO23/sLV8pu0ttve0bmdU3TSA6oznMP6EpB9HxJ9K+jNJ99m+TtIDkl6IiGslvdB6DKBPtQ17RByMiDda94ck7ZI0V9Kdkja2nrZR0l29ahJA987qGnS250taKmmbpNkRcVAa+Q/B9mUF66yTtK67NgF0a9xhtz1V0m8l/SgiPiuboHG0iFgvaX3rNThBBzRkXENvtidqJOi/jognW4sP2Z7Tqs+RdLg3LQKoQts9u0d24b+QtCsifjqqtFnSWkmPtm6f6kmH6Klp06aV1q+//vrS+iWXXFJlO5Xq596aMJ7D+Jsk/aWkt2yfHnR9UCMhf8L29yS9L+k7vWkRQBXahj0iXpZU9AH9W9W2A6BX+LoskARhB5Ig7EAShB1IgrADSdQ6ZbNtTZo0qbB+7NixGruBJA0NDZXWL7yw1n8ilXryySfbPykR9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kASXkkZjVq5cWVpfu3Ztaf35558vrZddLvrWW28tXbeflfW+detWffrpp0zZDGRG2IEkCDuQBGEHkiDsQBKEHUiCsANJnLs/VsY5b+bMmaX1ZcuWldbb/RZ/zpw5Z91TXRYvXlxY2717d+m6N954Y2HtzTffLKyxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJMYzP/sVkn4l6U8knZK0PiJ+bvthSfdK+kPrqQ9GxLO9ahT9qWweAEkaHh4urG3evLl03W3btpXWDx06VFq/4447Suu9NH369NL61VdfXVjbsWNH6brvvPNOYe3o0aOFtfF8qeaEpB9HxBu2p0l63faWVu1nEfGP43gNAA0bz/zsByUdbN0fsr1L0txeNwagWmf1md32fElLJZ0+vvqB7R22H7M9o2CddbYHbA901SmArow77LanSvqtpB9FxGeS/lXSAklLNLLn/6ex1ouI9RGxPCKWV9AvgA6NK+y2J2ok6L+OiCclKSIORcTJiDglaYOkFb1rE0C32obdtiX9QtKuiPjpqOWjf1L0bUmD1bcHoCptLyVte6Wk/5L0lkaG3iTpQUl3a+QQPiTtk/T91sm8stfiUtJjWLhwYWm93bTJg4P8P4v/FxFjXkp6PGfjX5Y01sqMqQPnEL5BByRB2IEkCDuQBGEHkiDsQBKEHUiCS0nXoN04+s0331xaf/XVV6tsB0mxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNr+nr3Sjdl/kPQ/oxbNkvRRbQ2cnX7trV/7kuitU1X2dlVEXDpWodawf23j9kC/XpuuX3vr174keutUXb1xGA8kQdiBJJoO+/qGt1+mX3vr174keutULb01+pkdQH2a3rMDqAlhB5JoJOy2b7P9ju29th9ooocitvfZfsv29qbnp2vNoXfY9uCoZTNtb7G9p3U75hx7DfX2sO0PWu/ddtu3N9TbFbZftL3L9k7bP2wtb/S9K+mrlvet9s/sti+QtFvSLZL2S3pN0t0R8d+1NlLA9j5JyyOi8S9g2P6mpD9K+lVEXN9a9g+SPomIR1v/Uc6IiL/pk94elvTHpqfxbs1WNGf0NOOS7pL0V2rwvSvp6y9Uw/vWxJ59haS9EfFeRAxL+o2kOxvoo+9FxEuSPjlj8Z2SNrbub9TIP5baFfTWFyLiYES80bo/JOn0NOONvnclfdWiibDPlfT7UY/3q7/mew9Jz9t+3fa6ppsZw+zT02y1bi9ruJ8ztZ3Gu05nTDPeN+9dJ9Ofd6uJsI81lVQ/jf/dFBHLJK2RdF/rcBXjM65pvOsyxjTjfaHT6c+71UTY90u6YtTjeZIONNDHmCLiQOv2sKRN6r+pqA+dnkG3dXu44X7+Tz9N4z3WNOPqg/euyenPmwj7a5Kutf0N25MkfVfS5gb6+BrbU1onTmR7iqRb1X9TUW+WtLZ1f62kpxrs5Sv6ZRrvomnG1fB71/j05xFR+5+k2zVyRv5dSX/bRA8FfV0t6c3W386me5P0uEYO645r5Ijoe5IukfSCpD2t25l91Nu/a2Rq7x0aCdachnpbqZGPhjskbW/93d70e1fSVy3vG1+XBZLgG3RAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/AsYGVR5QANJsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(block4_pool_features[0][...,4], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컨볼루션이 앞에 있을 수록, 전체적인 그림을 잡고 앞에 있을 수록 조금 추상적인 세부적인 특징을 잡아낸다.\n",
    "\n",
    " - predict: 피드포워드 시키는 것 ★★★\n",
    " \n",
    " - feature: 디멘션이다 ★★★ 많으면 좋은데, 데이터 더 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서블로 이미지 복습\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "### 이미지 불러오는 방식 2가지\n",
    "\n",
    " - 이미지 데이터 제너레이터\n",
    " - 텐서플로 io이용해서 bytes 형태로 불러오는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 제너레이터 없이 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [i for i in os.listdir(data_dir) if i !='LICENSE.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3670"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 제너레이터는 축복이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 성능 높이려면 어쩔 수 없이 crop을 해줘야 한다. 그런데 우리는 시간 없으니까 그냥 resize 쓸 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16부터는 민맥스 안쓰고 스탠다드라이제이션 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 224 # 이미지넷 전용\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE) # next할 때마다 몇 개씩 넣을지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = list(CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data_gen)\n",
    "train_data_gen.class_indices # 폴더명이 알아서 클래스로 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 케라스에서 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top = True,\n",
    "            weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in vgg.layers:\n",
    "    temp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2775792c1c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in temp:\n",
    "    i.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for j in temp:\n",
    "    print(j.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 134,281,029\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 69s 1s/step - loss: 1.7290 - categorical_accuracy: 0.3771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2771ef5e608>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer learning 5 flower fit using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "                                         fname='flower_photos', untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = str(data_dir/'*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\white\\\\.keras\\\\datasets\\\\flower_photos\\\\*\\\\*.jpg'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5694, shape=(), dtype=string, numpy=b'C:\\\\Users\\\\white\\\\.keras\\\\datasets\\\\flower_photos\\\\daisy\\\\100080576_f52e8ee070_n.jpg'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(list_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5700, shape=(), dtype=string, numpy=b'C:\\\\Users\\\\white\\\\.keras\\\\datasets\\\\flower_photos\\\\daisy\\\\100080576_f52e8ee070_n.jpg'>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_test = next(iter(list_ds))\n",
    "file_path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(file_path):\n",
    "    return CLASS_NAMES == tf.strings.split(file_path, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5762, shape=(), dtype=string, numpy=b'daisy'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.split(file_path_test, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5826, shape=(5,), dtype=bool, numpy=array([ True, False, False, False, False])>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES == tf.strings.split(file_path_test, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "def decode_img(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    npy_img = tf.image.decode_jpeg(img, channels=3)\n",
    "    npy_img2 = tf.image.convert_image_dtype(npy_img, dtype=tf.float32)\n",
    "    return tf.image.resize(npy_img2, [IMAGE_WIDTH, IMAGE_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5836, shape=(224, 224, 3), dtype=float32, numpy=\n",
       "array([[[0.5240897 , 0.53193283, 0.5201681 ],\n",
       "        [0.5434174 , 0.55126053, 0.5394958 ],\n",
       "        [0.5613202 , 0.5691633 , 0.5579101 ],\n",
       "        ...,\n",
       "        [0.60028005, 0.60028005, 0.5924369 ],\n",
       "        [0.60049963, 0.60049963, 0.5926565 ],\n",
       "        [0.5860057 , 0.5860057 , 0.57816255]],\n",
       "\n",
       "       [[0.5230655 , 0.53090864, 0.51753455],\n",
       "        [0.5423932 , 0.55023634, 0.53847164],\n",
       "        [0.5601135 , 0.5679566 , 0.5561919 ],\n",
       "        ...,\n",
       "        [0.60028005, 0.60028005, 0.5924369 ],\n",
       "        [0.601777  , 0.601777  , 0.5939339 ],\n",
       "        [0.58216846, 0.58216846, 0.5743253 ]],\n",
       "\n",
       "       [[0.5201681 , 0.5263043 , 0.5076456 ],\n",
       "        [0.54059315, 0.5467294 , 0.53155077],\n",
       "        [0.559008  , 0.5634373 , 0.55337954],\n",
       "        ...,\n",
       "        [0.5969881 , 0.5969881 , 0.58914495],\n",
       "        [0.59656304, 0.59656304, 0.5887199 ],\n",
       "        [0.57317483, 0.57317483, 0.5653317 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.17254902, 0.18823531, 0.09803922],\n",
       "        [0.17254902, 0.18823531, 0.09803922],\n",
       "        [0.17254902, 0.18823531, 0.09803922],\n",
       "        ...,\n",
       "        [0.50037587, 0.4964543 , 0.48076802],\n",
       "        [0.49803925, 0.49411768, 0.4784314 ],\n",
       "        [0.49803925, 0.49411768, 0.4784314 ]],\n",
       "\n",
       "       [[0.17254902, 0.18823531, 0.09803922],\n",
       "        [0.17254902, 0.18823531, 0.09803922],\n",
       "        [0.17254902, 0.18823531, 0.09803922],\n",
       "        ...,\n",
       "        [0.5021677 , 0.49824616, 0.4825599 ],\n",
       "        [0.50093675, 0.49701518, 0.4813289 ],\n",
       "        [0.50093675, 0.49701518, 0.4813289 ]],\n",
       "\n",
       "       [[0.16896877, 0.18465506, 0.09445897],\n",
       "        [0.16896877, 0.18465506, 0.09445897],\n",
       "        [0.1692245 , 0.18491077, 0.09471471],\n",
       "        ...,\n",
       "        [0.5058211 , 0.50189954, 0.48621327],\n",
       "        [0.5055411 , 0.5016195 , 0.4859332 ],\n",
       "        [0.5083542 , 0.5044326 , 0.48874635]]], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.io.read_file(file_path_test)\n",
    "npy_img = tf.image.decode_jpeg(img, channels=3)\n",
    "npy_img2 = tf.image.convert_image_dtype(npy_img, dtype=tf.float32)\n",
    "tf.image.resize(npy_img2, [IMAGE_WIDTH, IMAGE_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    decoded_img = decode_img(file_path)\n",
    "    label = get_labels(file_path)\n",
    "    return decoded_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=5846, shape=(224, 224, 3), dtype=float32, numpy=\n",
       " array([[[0.5240897 , 0.53193283, 0.5201681 ],\n",
       "         [0.5434174 , 0.55126053, 0.5394958 ],\n",
       "         [0.5613202 , 0.5691633 , 0.5579101 ],\n",
       "         ...,\n",
       "         [0.60028005, 0.60028005, 0.5924369 ],\n",
       "         [0.60049963, 0.60049963, 0.5926565 ],\n",
       "         [0.5860057 , 0.5860057 , 0.57816255]],\n",
       " \n",
       "        [[0.5230655 , 0.53090864, 0.51753455],\n",
       "         [0.5423932 , 0.55023634, 0.53847164],\n",
       "         [0.5601135 , 0.5679566 , 0.5561919 ],\n",
       "         ...,\n",
       "         [0.60028005, 0.60028005, 0.5924369 ],\n",
       "         [0.601777  , 0.601777  , 0.5939339 ],\n",
       "         [0.58216846, 0.58216846, 0.5743253 ]],\n",
       " \n",
       "        [[0.5201681 , 0.5263043 , 0.5076456 ],\n",
       "         [0.54059315, 0.5467294 , 0.53155077],\n",
       "         [0.559008  , 0.5634373 , 0.55337954],\n",
       "         ...,\n",
       "         [0.5969881 , 0.5969881 , 0.58914495],\n",
       "         [0.59656304, 0.59656304, 0.5887199 ],\n",
       "         [0.57317483, 0.57317483, 0.5653317 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.17254902, 0.18823531, 0.09803922],\n",
       "         [0.17254902, 0.18823531, 0.09803922],\n",
       "         [0.17254902, 0.18823531, 0.09803922],\n",
       "         ...,\n",
       "         [0.50037587, 0.4964543 , 0.48076802],\n",
       "         [0.49803925, 0.49411768, 0.4784314 ],\n",
       "         [0.49803925, 0.49411768, 0.4784314 ]],\n",
       " \n",
       "        [[0.17254902, 0.18823531, 0.09803922],\n",
       "         [0.17254902, 0.18823531, 0.09803922],\n",
       "         [0.17254902, 0.18823531, 0.09803922],\n",
       "         ...,\n",
       "         [0.5021677 , 0.49824616, 0.4825599 ],\n",
       "         [0.50093675, 0.49701518, 0.4813289 ],\n",
       "         [0.50093675, 0.49701518, 0.4813289 ]],\n",
       " \n",
       "        [[0.16896877, 0.18465506, 0.09445897],\n",
       "         [0.16896877, 0.18465506, 0.09445897],\n",
       "         [0.1692245 , 0.18491077, 0.09471471],\n",
       "         ...,\n",
       "         [0.5058211 , 0.50189954, 0.48621327],\n",
       "         [0.5055411 , 0.5016195 , 0.4859332 ],\n",
       "         [0.5083542 , 0.5044326 , 0.48874635]]], dtype=float32)>,\n",
       " <tf.Tensor: id=5910, shape=(5,), dtype=bool, numpy=array([ True, False, False, False, False])>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_path(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((224, 224, 3), (5,)), types: (tf.float32, tf.bool)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "            print(\"캐시가 실행되네요\")\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "            print(\"캐시가 실행될리가 있냐 씨발\")\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐시가 실행될리가 있냐 씨발\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((None, 224, 224, 3), (None, 5)), types: (tf.float32, tf.bool)>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_for_training(labeled_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg = VGG16(include_top = True,\n",
    "            weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in vgg.layers:\n",
    "    i.trainable = False\n",
    "    temp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for j in temp:\n",
    "    print(j.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2a793760448>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 134,281,029\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.6875"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐시가 실행될리가 있냐 씨발\n",
      "Train for 115.0 steps\n",
      "Epoch 1/5\n",
      "115/115 [==============================] - 18s 154ms/step - loss: 1.2378 - categorical_accuracy: 0.5785\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 0.9563 - categorical_accuracy: 0.6840\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 0.8551 - categorical_accuracy: 0.7223\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 0.7528 - categorical_accuracy: 0.7533\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 16s 135ms/step - loss: 0.8711 - categorical_accuracy: 0.7408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a79bb24e88>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "model.fit(prepare_for_training(labeled_ds), steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x2a5410afbc8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a78f639ac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a79361a888>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2a53e5bba88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a793629408>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a79364d488>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2a793660948>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a793666a88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a79367aa88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a793685fc8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2a7936ab448>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a7936ab548>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a7936c7588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a7936d6a48>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2a7936e4d48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a7936fac08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a793708e88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2a7937265c8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2a793734ac8>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x2a79373cc08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2a79373ed08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2a793752b48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2a79780d208>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = temp.copy()\n",
    "temp2.append(model.layers[-1])\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve에 넣을 def\n",
    "def model_compile():\n",
    "    model = Sequential(temp2)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670\n",
      "C:\\Users\\white\\.keras\\datasets\\flower_photos\\daisy\\100080576_f52e8ee070_n.jpg\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "file_path = str(data_dir)+'\\\\'\n",
    "class_list = CLASS_NAMES\n",
    "file_list_for_np = []\n",
    "for classes in class_list:\n",
    "    for file in glob.os.listdir(file_path+classes):\n",
    "        file_list_for_np.append(file_path+classes+'\\\\'+file)\n",
    "        \n",
    "        \n",
    "print(len(file_list_for_np))\n",
    "print(file_list_for_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3670, 224, 224, 3)\n",
      "(3670,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "train_x = np.stack([cv2.resize(cv2.imread(i), (224,224)) for i in file_list_for_np], axis = 0)\n",
    "train_y = np.array([i.split(os.path.sep)[-2] for i in file_list_for_np])\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐시가 실행될리가 있냐 씨발\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "learning_curve() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-153a941664cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m train_size, train_score, test_score = learning_curve(KerasClassifier(model_compile, epochs = 5), \n\u001b[1;32m----> 5\u001b[1;33m                                                      prepare_for_training(labeled_ds), cv=2, verbose=1)\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: learning_curve() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_size, train_score, test_score = learning_curve(KerasClassifier(model_compile, epochs = 5), \n",
    "                                                     train_x, train_y, cv=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a7da6019c8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn_evaluation\n",
    "sklearn_evaluation.plot.learning_curve(train_score, test_score, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 91: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ReadFile\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m         name, _ctx._post_execution_callbacks, filename)\n\u001b[0m\u001b[0;32m    604\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-54922846e566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-132-70f835e07350>\u001b[0m in \u001b[0;36mprocess_path\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdecoded_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecoded_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-130-f318cd817be5>\u001b[0m in \u001b[0;36mdecode_img\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mnpy_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnpy_img2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpy_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, name)\u001b[0m\n\u001b[0;32m    606\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         return read_file_eager_fallback(\n\u001b[1;32m--> 608\u001b[1;33m             filename, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    609\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[1;34m(filename, name, ctx)\u001b[0m\n\u001b[0;32m    655\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[1;32m--> 657\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m    658\u001b[0m   _execute.record_gradient(\n\u001b[0;32m    659\u001b[0m       \"ReadFile\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 91: invalid start byte"
     ]
    }
   ],
   "source": [
    "process_path(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_wid = 224\n",
    "img_hei = 224\n",
    "img_channel = 3\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == classes\n",
    "\n",
    "def preprocess(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img, channels = img_channel)\n",
    "    img = tf.image.resize(img, (img_wid, img_hei))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = img/255.0\n",
    "    label = get_label(file_path)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "output = list_ds.map(preprocess)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "inputs_tf_list = output.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.3384757, shape=(), dtype=float32) tf.Tensor(90.136246, shape=(), dtype=float32) -17.26717209815979\n",
      "tf.Tensor(0.2603048, shape=(), dtype=float32) tf.Tensor(91.63487, shape=(), dtype=float32) -17.2177631855011\n",
      "tf.Tensor(0.26098874, shape=(), dtype=float32) tf.Tensor(91.280655, shape=(), dtype=float32) -17.074421167373657\n",
      "tf.Tensor(0.2469309, shape=(), dtype=float32) tf.Tensor(91.621254, shape=(), dtype=float32) -17.335543870925903\n",
      "tf.Tensor(0.2422418, shape=(), dtype=float32) tf.Tensor(91.613075, shape=(), dtype=float32) -17.152166843414307\n"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "EPOCHS = 5\n",
    "import time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    for images, labels in inputs_tf_list:\n",
    "        train_step(images, labels)\n",
    "    end_time = start_time-time.time()\n",
    "    print(train_loss.result(), train_accuracy.result()*100, end_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0-GPU",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
