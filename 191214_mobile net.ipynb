{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 파이프라인이란, 일종의 데이터 흐름이다. 잘 구축해두면, 데이터만 바꾸면 싹 다 바뀐다.\n",
    " \n",
    "### prefetch 개념\n",
    "\n",
    "미리 땡겨오는 개념이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    GlobalAveragePooling2D(input_shape = (4, 4, 3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_6 ( (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ]],\n",
    "            [[1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ]],\n",
    "            [[1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ]],\n",
    "             [[1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3, ],\n",
    "         [1, 2, 3,]]])\n",
    "x = x[np.newaxis, ...]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel filter 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, GlobalMaxPool2D\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = tfds.load('mnist',\n",
    "                  as_supervised=True,\n",
    "                  with_info=True,\n",
    "                  split = tfds.Split.TRAIN.subsplit(weighted = (7, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, valid_input, test_input), metadata = mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1 # -1 ~ 1 사이로 스케일링 해준다. 하이퍼볼릭 탄젠트 방식.\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_input.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    GlobalMaxPool2D(input_shape = (28, 28, 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_max_pooling2d (Global (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'kernel_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-ab66cd22a9b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'kernel_'"
     ]
    }
   ],
   "source": [
    "tf.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model = Sequential([\n",
    "     Dense(1, input_shape = (3, 3), # 데이터가 1개일 때 input_shape을 적는다.\n",
    "           use_bias = False,\n",
    "#            kernel_initializer = tf.keras.initializers.he_normal(seed=None), # 가중치 초기화\n",
    "           kernel_initializer = tf.keras.initializers.ones())\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = Sequential([\n",
    "     Dense(2, input_shape = (3, 3),\n",
    "          kernel_initializer = 'ones'),\n",
    "     Dense(2, kernel_initializer = 'ones'),\n",
    "     ReLU(),\n",
    "     Flatten()\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 3, 2)              8         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3, 2)              6         \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(9).reshape(1, 3, 3)\n",
    "b = np.arange(18).reshape(2, 3, 3)\n",
    "c = np.arange(24).reshape(2, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b = np.array([[[1, 2, 3],[1, 2, 3],[1, 2, 3]],\n",
    "#              [[1, 2, 3], [1, 2, 3], [1, 2, 3]]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  6., 24., 24., 42., 42.],\n",
       "       [60., 60., 78., 78., 96., 96.]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(c).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱하는 애들은 행렬곱이기 때문에 첫 번재 행의 모양을 따라가는 것이다. 그래서 Dense shape의 모양이 변한다.\n",
    "\n",
    "Flatten은 레코드 구성방식 C방식에 따라서, 로우마다 짤라서 붙여준다. ★"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모바일넷 컨볼루션 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "model = MobileNetV2(include_top = False,\n",
    "                    input_shape = (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 33, 33, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 16, 16, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # sequence 모델이 아니기 때문에, connected to라는 것이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential에 안 넣고 model 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, ReLU, Conv2D, BatchNormalization, MaxPool2D, GlobalAvgPool2D\n",
    "\n",
    "\n",
    "input_layer = Input(shape = (32, 32))\n",
    "x1 = Dense(2, kernel_initializer = 'ones')(input_layer)\n",
    "\n",
    "model2 = Model(input_layer, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 32, 32)]          0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "★★★ activatoin 함수를 따로 빼서 쓰는 이유는, 디버깅하기 쉽기 때문이다. summary했을 때, dense 내부 activatoin함수를 모르기 때문에 밖으로 빼서 아는 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(25).reshape(5, 5)\n",
    "b = np.ones((3, 3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "row = a.shape[0] - b.shape[0] + 1\n",
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.,  63.,  72.],\n",
       "       [ 99., 108., 117.],\n",
       "       [144., 153., 162.]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "\n",
    "for i in range(a.shape[0] - b.shape[0] + 1):\n",
    "    for j in range(a.shape[0] - b.shape[0] + 1):\n",
    "        temp.append(np.sum(a[i:i+3, j:j+3]*b))\n",
    "        \n",
    "# np.array(temp).mean(axis = 0)\n",
    "np.array(temp).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(2, (3, 3), \n",
    "           kernel_initializer = 'ones',\n",
    "           input_shape = (10, 10, 1)),\n",
    "    GlobalAvgPool2D(), # 각 필터를 평균잡는 것\n",
    "#     Conv2D(2, (3, 3), \n",
    "#            kernel_initializer = 'ones'),\n",
    "#     BatchNormalization()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 2)           20        \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[445.5, 445.5]], dtype=float32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model.predict(a)\n",
    "t[..., 0].mean()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21856, shape=(28, 28, 1), dtype=float32, numpy=\n",
       "array([[[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.6313726 ],\n",
       "        [ 0.22352946],\n",
       "        [ 0.88235295],\n",
       "        [ 0.99215686],\n",
       "        [ 1.        ],\n",
       "        [ 0.88235295],\n",
       "        [-0.5294118 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.94509804],\n",
       "        [-0.04313725],\n",
       "        [ 0.92156863],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.94509804],\n",
       "        [ 0.6862745 ],\n",
       "        [ 0.77254903],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.1686275 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.75686276],\n",
       "        [ 0.30196083],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.9529412 ],\n",
       "        [ 0.02745104],\n",
       "        [-0.60784316],\n",
       "        [-1.        ],\n",
       "        [-0.69411767],\n",
       "        [ 0.8901961 ],\n",
       "        [ 0.1686275 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.58431375],\n",
       "        [ 0.38823533],\n",
       "        [ 0.05882359],\n",
       "        [-0.56078434],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.64705884],\n",
       "        [ 0.9137255 ],\n",
       "        [ 0.1686275 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.06666666],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.1686275 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.24705887],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.11372554],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.77254903],\n",
       "        [ 0.9843137 ],\n",
       "        [-0.56078434],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.12156862],\n",
       "        [ 0.99215686],\n",
       "        [ 0.5294118 ],\n",
       "        [-0.9843137 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.96862745],\n",
       "        [ 0.5294118 ],\n",
       "        [ 0.99215686],\n",
       "        [ 0.45098042],\n",
       "        [-0.03529412],\n",
       "        [-0.25490195],\n",
       "        [-0.81960785],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.4980392 ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.99215686],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.7490196 ],\n",
       "        [-0.85882354],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.7019608 ],\n",
       "        [ 0.99215686],\n",
       "        [ 1.        ],\n",
       "        [ 0.60784316],\n",
       "        [-0.25490195],\n",
       "        [ 0.3803922 ],\n",
       "        [ 0.99215686],\n",
       "        [ 0.09803927],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.21568626],\n",
       "        [ 0.9529412 ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.22352946],\n",
       "        [-0.8117647 ],\n",
       "        [-1.        ],\n",
       "        [-0.70980394],\n",
       "        [ 0.90588236],\n",
       "        [ 0.75686276],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.7254902 ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.10588241],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.26274514],\n",
       "        [ 0.94509804],\n",
       "        [-0.5372549 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.60784316],\n",
       "        [-0.34117645],\n",
       "        [-0.827451  ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.10588241],\n",
       "        [ 0.9843137 ],\n",
       "        [-0.41176468],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.10588241],\n",
       "        [ 0.9843137 ],\n",
       "        [-0.41176468],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.16078436],\n",
       "        [ 0.9843137 ],\n",
       "        [-0.41176468],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.84313726],\n",
       "        [ 0.92941177],\n",
       "        [-0.6313726 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.64705884],\n",
       "        [ 0.92156863],\n",
       "        [ 0.67058825],\n",
       "        [-0.9764706 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-0.8509804 ],\n",
       "        [ 0.78039217],\n",
       "        [ 0.9843137 ],\n",
       "        [-0.5294118 ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [ 0.082353  ],\n",
       "        [ 0.9843137 ],\n",
       "        [ 0.16078436],\n",
       "        [-0.90588236],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]],\n",
       "\n",
       "       [[-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ],\n",
       "        [-1.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for img, label in train_data.take(1):\n",
    "    pass\n",
    "\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0-GPU",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
