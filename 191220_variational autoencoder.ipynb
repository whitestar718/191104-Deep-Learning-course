{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AggregationMethod',\n",
       " 'Assert',\n",
       " 'CriticalSection',\n",
       " 'DType',\n",
       " 'DeviceSpec',\n",
       " 'GradientTape',\n",
       " 'Graph',\n",
       " 'IndexedSlices',\n",
       " 'IndexedSlicesSpec',\n",
       " 'Module',\n",
       " 'Operation',\n",
       " 'OptionalSpec',\n",
       " 'RaggedTensor',\n",
       " 'RaggedTensorSpec',\n",
       " 'RegisterGradient',\n",
       " 'SparseTensor',\n",
       " 'SparseTensorSpec',\n",
       " 'Tensor',\n",
       " 'TensorArray',\n",
       " 'TensorArraySpec',\n",
       " 'TensorShape',\n",
       " 'TensorSpec',\n",
       " 'TypeSpec',\n",
       " 'UnconnectedGradients',\n",
       " 'Variable',\n",
       " 'VariableAggregation',\n",
       " 'VariableSynchronization',\n",
       " '_LazyLoader',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__compiler_version__',\n",
       " '__cxx11_abi_flag__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__monolithic_build__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_absolute_import',\n",
       " '_api',\n",
       " '_division',\n",
       " '_forward_module',\n",
       " '_importlib',\n",
       " '_m',\n",
       " '_print_function',\n",
       " '_root_estimator',\n",
       " '_sys',\n",
       " '_top_level_modules',\n",
       " '_types',\n",
       " 'abs',\n",
       " 'acos',\n",
       " 'acosh',\n",
       " 'add',\n",
       " 'add_n',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_dtype',\n",
       " 'as_string',\n",
       " 'asin',\n",
       " 'asinh',\n",
       " 'assert_equal',\n",
       " 'assert_greater',\n",
       " 'assert_less',\n",
       " 'assert_rank',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atanh',\n",
       " 'audio',\n",
       " 'autograph',\n",
       " 'batch_to_space',\n",
       " 'bfloat16',\n",
       " 'bitcast',\n",
       " 'bitwise',\n",
       " 'bool',\n",
       " 'boolean_mask',\n",
       " 'broadcast_dynamic_shape',\n",
       " 'broadcast_static_shape',\n",
       " 'broadcast_to',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'clip_by_global_norm',\n",
       " 'clip_by_norm',\n",
       " 'clip_by_value',\n",
       " 'compat',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'cond',\n",
       " 'config',\n",
       " 'constant',\n",
       " 'constant_initializer',\n",
       " 'control_dependencies',\n",
       " 'convert_to_tensor',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'cumsum',\n",
       " 'custom_gradient',\n",
       " 'data',\n",
       " 'debugging',\n",
       " 'device',\n",
       " 'distribute',\n",
       " 'divide',\n",
       " 'double',\n",
       " 'dtypes',\n",
       " 'dynamic_partition',\n",
       " 'dynamic_stitch',\n",
       " 'edit_distance',\n",
       " 'einsum',\n",
       " 'ensure_shape',\n",
       " 'equal',\n",
       " 'errors',\n",
       " 'estimator',\n",
       " 'examples',\n",
       " 'executing_eagerly',\n",
       " 'exp',\n",
       " 'expand_dims',\n",
       " 'experimental',\n",
       " 'extract_volume_patches',\n",
       " 'eye',\n",
       " 'feature_column',\n",
       " 'fill',\n",
       " 'fingerprint',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'floor',\n",
       " 'foldl',\n",
       " 'foldr',\n",
       " 'function',\n",
       " 'gather',\n",
       " 'gather_nd',\n",
       " 'get_logger',\n",
       " 'get_static_value',\n",
       " 'grad_pass_through',\n",
       " 'gradients',\n",
       " 'graph_util',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'group',\n",
       " 'guarantee_const',\n",
       " 'half',\n",
       " 'hessians',\n",
       " 'histogram_fixed_width',\n",
       " 'histogram_fixed_width_bins',\n",
       " 'identity',\n",
       " 'identity_n',\n",
       " 'image',\n",
       " 'import_graph_def',\n",
       " 'init_scope',\n",
       " 'initializers',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'io',\n",
       " 'is_tensor',\n",
       " 'keras',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'lite',\n",
       " 'load_library',\n",
       " 'load_op_library',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'lookup',\n",
       " 'losses',\n",
       " 'make_ndarray',\n",
       " 'make_tensor_proto',\n",
       " 'map_fn',\n",
       " 'math',\n",
       " 'matmul',\n",
       " 'matrix_square_root',\n",
       " 'maximum',\n",
       " 'meshgrid',\n",
       " 'metrics',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'name_scope',\n",
       " 'negative',\n",
       " 'nest',\n",
       " 'newaxis',\n",
       " 'nn',\n",
       " 'no_gradient',\n",
       " 'no_op',\n",
       " 'nondifferentiable_batch_function',\n",
       " 'norm',\n",
       " 'not_equal',\n",
       " 'numpy_function',\n",
       " 'one_hot',\n",
       " 'ones',\n",
       " 'ones_initializer',\n",
       " 'ones_like',\n",
       " 'optimizers',\n",
       " 'pad',\n",
       " 'parallel_stack',\n",
       " 'pow',\n",
       " 'print',\n",
       " 'py_function',\n",
       " 'qint16',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'quantization',\n",
       " 'queue',\n",
       " 'quint16',\n",
       " 'quint8',\n",
       " 'ragged',\n",
       " 'random',\n",
       " 'random_normal_initializer',\n",
       " 'random_uniform_initializer',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'raw_ops',\n",
       " 'realdiv',\n",
       " 'recompute_grad',\n",
       " 'reduce_all',\n",
       " 'reduce_any',\n",
       " 'reduce_logsumexp',\n",
       " 'reduce_max',\n",
       " 'reduce_mean',\n",
       " 'reduce_min',\n",
       " 'reduce_prod',\n",
       " 'reduce_sum',\n",
       " 'register_tensor_conversion_function',\n",
       " 'required_space_to_batch_paddings',\n",
       " 'reshape',\n",
       " 'resource',\n",
       " 'reverse',\n",
       " 'reverse_sequence',\n",
       " 'roll',\n",
       " 'round',\n",
       " 'saturate_cast',\n",
       " 'saved_model',\n",
       " 'scalar_mul',\n",
       " 'scan',\n",
       " 'scatter_nd',\n",
       " 'searchsorted',\n",
       " 'sequence_mask',\n",
       " 'sets',\n",
       " 'shape',\n",
       " 'shape_n',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'signal',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'size',\n",
       " 'slice',\n",
       " 'sort',\n",
       " 'space_to_batch',\n",
       " 'space_to_batch_nd',\n",
       " 'sparse',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'stop_gradient',\n",
       " 'strided_slice',\n",
       " 'string',\n",
       " 'strings',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'switch_case',\n",
       " 'sysconfig',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensor_scatter_nd_add',\n",
       " 'tensor_scatter_nd_sub',\n",
       " 'tensor_scatter_nd_update',\n",
       " 'tensordot',\n",
       " 'test',\n",
       " 'tile',\n",
       " 'timestamp',\n",
       " 'tpu',\n",
       " 'train',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncatediv',\n",
       " 'truncatemod',\n",
       " 'tuple',\n",
       " 'uint16',\n",
       " 'uint32',\n",
       " 'uint64',\n",
       " 'uint8',\n",
       " 'unique',\n",
       " 'unique_with_counts',\n",
       " 'unravel_index',\n",
       " 'unstack',\n",
       " 'variable_creator_scope',\n",
       " 'variant',\n",
       " 'vectorized_map',\n",
       " 'version',\n",
       " 'where',\n",
       " 'while_loop',\n",
       " 'xla',\n",
       " 'zeros',\n",
       " 'zeros_initializer',\n",
       " 'zeros_like']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - manifold leaning\n",
    " - sparse autoencoder: 차원을 줄이지 않고 늘렸다가 줄이는 것.\n",
    " - 핵심은 오토인코더는 앞뒤가 똑같다는 것이다.\n",
    " - PCA하고 auto encoder랑 같이 못 쓴다. 뉴럴네트워크 기반 모델에 쓰여서, end-to-end 모델에 쓰인다.\n",
    " \n",
    "오토인코더의 최고의 문제점은 그림이 너무 희미하게 나온다는 것이다. 희미한 특성 때문에, gan을 더 많이 쓰는 이유다.\n",
    "\n",
    "---\n",
    "\n",
    "logistic regression vs naive bayes -> 기계학습 하는 사람들은 반드시 읽어봐야 하는 모델. no free lunch을 배울 때, 제일 먼저 배우는 것이 로지스틱 리그레션과 나이브 베이즈 등등을 베운다. 뭐 각설하고, 판별모델 vs 생성모델로도 분류할 수 있는데, 일반적인 판별모델이 뉴럴 네트워크이고 생성모델은 갠과 오토인코더 계열이다. 그런데 분포를 찾을 때는 싹 다 확률 기반으로 찾는다. 확률은 또 2가지 기반으로 나뉘는데, 과거기반으로 찾는 베이지안 확률과 숫자만 가지고 노는 애들이다.\n",
    "\n",
    " - ml 방식: 남자에게 머리카락이 나올 확률 / 여자에게 머리카락이 나올 확률을 나와서 그것만 비교하는 것이다.\n",
    " - MAP: 머리카락이 발견됬을 때, 남자인 확률, 여자인 확률을 구하는 것이다. 직접 구하기 어려워서 간접적으로 베이지안 룰을 이용해서 구한다. \n",
    " \n",
    "https://www.tensorflow.org/probability?hl=ko\n",
    "\n",
    "연산복잡도를 만드는 방법 중의 하나이다. 위의 사이트에 관심을 가지면 망한다. 선생님 말 듣자... 암튼 뭐 manifold라는 것은 차원을 축소시켜도 고차원에서 있는 특성들이 살아있다는 것이다. 그러면 latent 변수 (숨어있는 변수) 만 잘 찾으면, 차원에 상관없이 결과를 잘 만들어낼 수 있다. varaitional autoencoder는 평균과 표준편차 개념이 들어간다. 그래서 정규화가 인코더와 디코더에 들어가게 된다. 이 가운데 있는 레이어를 이용해서, 새로운 결과를 창출할 수 있다. 이 녀석을 이용해서 새로운 분포를 찾아내서, 그 분포에 따른 결과를 생성한다. 대부분 정규분포를 가정한다. 복잡한 분포는 대부분 정규분포를 따를 수 있기 때문. \n",
    "\n",
    "여담이지만, 디코더를 갠으로 바꿀 수도 있다. 그런데 갠은 학습이 안되는 단점이 있다. 애초에 체리피킹 논문이라고 발표를 했다. 그래서 나중에 나온 논문들은 갠을 어떻게 잘 학습시킬 것이냐라는 문제를 다룬다. 다시 본론으로 돌아와서, 분포를 찾아야 하는데 결국 이건 추정이다. 정확하게 찾는 방식이 있고, 대충 추정하는 방식이 있다. variational 방식은 정확하게 찾으려는 계열 중에서, 좀 대충 찾는 방식이다. 다시 말하면, 모델을 가정하고 (우리의 경우는 정규분포) 이 가정을 정확하게는 찾지 못하고, 근사치를 이용해서 대충찾는 방법이다. 대충찾는게 마코프 체인인데, 몰라도 된다. 갠도 모델을 안 만든다.\n",
    "\n",
    "컴퓨터 사이언스의 관점은 새로운 것들 받고, 성능만 좋으면 장땡이다. 나도 계속 이 분야로 나가려면 아마 이 관점을 따라야 할 것이다. 지금 은근히 잘 나가는 걸지도?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras blog auto encoder\n",
    "\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "역사적으로 항상 풀리 커넥티드가 성공하면, 컨볼루션데 도전한다. 갠도 마찬가지다. 풀리 커넥티드한 오토 인코더와 비교했을 때, 훨씬 더 깔끔하게 결과가 나온다. 흐리지 않고 말이다.\n",
    "\n",
    "# denoising\n",
    "\n",
    "노이즈는 고유한 특성이 아니다. 이 것을 제거하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노이즈 값을 더해서, 랜덤으로 노이즈를 생성하는 방식이다. 그 뒤에 클립을 이용해서 0부터 1가지의 값으로 잘라주었는데 이렇게 하는 이유는 뉴럴네트워크에서 좋은 성능을 주기 때문이다. 포토샵에서도 이런게 있는데, 평균을 내서 이미지를 조금 흐려지게 만든다. 여기까지는 그냥 데이터 만드는 부분이니까 크게 신경쓰지 마라.\n",
    "\n",
    "w, b는 오버피팅 시켜도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18d1e087fc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_noisy.shape\n",
    "plt.imshow(x_train_noisy[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1619 - val_loss: 0.1163\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1133 - val_loss: 0.1084\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1078 - val_loss: 0.1051\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1051 - val_loss: 0.1028\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1032 - val_loss: 0.1017\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1019 - val_loss: 0.1003\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1008 - val_loss: 0.0994\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1000 - val_loss: 0.0990\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0988 - val_loss: 0.0977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d269c5dc8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder.predict(x_train_noisy[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_train_noisy[0].reshape(28, 28), cmap = 'gray')\n",
    "plt.title('origin')\n",
    "plt.imshow(a[0].reshape(28, 28), cmap = 'gray')\n",
    "plt.title('decoded')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 안 나타나는 중요한 특징은 사라질 수도 있다. 얘는 손실 압축 개념이기 때문에 노이즈를 없앨 수 있다. 점들이 다른 형태로 나올 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add, Average, Concatenate, Dot\n",
    "\n",
    "샹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Add, Input, Average, Concatenate, Dot\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape = (2, 2))\n",
    "\n",
    "x1 = Dense(2, activation='relu', kernel_initializer='ones')(input1)\n",
    "x2 = Dense(2, activation='relu', kernel_initializer='ones')(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3 = Average()([x1, x2])\n",
    "layer4 = Concatenate()([x1, x2])\n",
    "layer5 = Dot(axes =2)([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = Model(input1, layer3)\n",
    "con = Model(input1, layer4)\n",
    "dot = Model(input1, layer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [3, 4]])\n",
    "x = x[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3., 3.],\n",
       "        [7., 7.]]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mo.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = con.predict(x)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3., 3., 3., 3.],\n",
       "        [7., 7., 7., 7.]]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[18., 42.],\n",
       "        [42., 98.]]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate에서 추가될 때, 행개념으로 추가될까 열 개념으로 추가될까? 기본적으로 열 개념으로 추가된다. 행렬 연산이 가능하려면, 행은 고정되어 있지만, 열은 알아서 자동적으로 계산을 해주는데, 그래서 열 개념이 좀 더 유연하다.\n",
    "\n",
    "람다 레이어는 한 번 쓰면 사라져 버린다. 함수를 인자로 받아서, 앞의 레이어의 값을 변화시켜주는게 람다이다. 람다 레이어는 지가 함수를 받아서, 앞에서 받은 결과값을 이 함수를 실행해서 다음 레이어에 던져누는 것이다. ★★★ 다양한 연산을 이 람다를 통해서 던져줄 수 있다.\n",
    "\n",
    "람다의 아웃풋 레이어에 아웃풋 옵션이 있는데, 이건 안해줘도 된다. 왜냐면 텐서플로 기반은 알아서 맞춰주기 때문이다. 다른 프레임워크는 이걸 맞춰줘야 하기 때문에 굳이 코딩에 output을 넣어두었다.\n",
    "\n",
    "### 리 파라미터라이즈 테크닉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "intermediate_dim = 32\n",
    "latent_dim = 16\n",
    "original_dim = 784\n",
    "epsilon_std = 1\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Functional models may only specify `name` and `trainable` keyword arguments during initialization. Got an unexpected argument:', 'output')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-360588f11347>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0m_h_decoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0m_x_decoded_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_h_decoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_x_decoded_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m    166\u001b[0m       \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m       \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     generic_utils.validate_kwargs(\n\u001b[0;32m    256\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'trainable'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;34m'Functional models may only specify `name` and `trainable` keyword '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         'arguments during initialization. Got an unexpected argument:')\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# Normalize and set self.inputs, self.outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ('Functional models may only specify `name` and `trainable` keyword arguments during initialization. Got an unexpected argument:', 'output')"
     ]
    }
   ],
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "Add()\n",
    "generator = Model(decoder_input, _x_decoded_mean, output = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(16, 784)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (16, 32)             25120       input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (16, 16)             528         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (16, 16)             528         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (16, 16)             0           dense_53[0][0]                   \n",
      "                                                                 dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                multiple             544         lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                multiple             25872       dense_55[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 52,592\n",
      "Trainable params: 52,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        [(16, 784)]               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (16, 32)                  25120     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (16, 16)                  528       \n",
      "=================================================================\n",
      "Total params: 25,648\n",
      "Trainable params: 25,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                multiple             544         input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                multiple             25872       dense_55[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 784)          0           dense_56[1][0]                   \n",
      "                                                                 dense_56[1][0]                   \n",
      "==================================================================================================\n",
      "Total params: 26,416\n",
      "Trainable params: 26,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary() # 디코더 부분을 제너레이터라고 부른다. 이제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When passing a list as loss, it should have one entry per model outputs. The model has 1 outputs, but you passed loss=[<function vae_loss1 at 0x0000018F68A0EDC8>, <function vae_loss2 at 0x0000018F68A0EA68>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-178a80748a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m vae.compile(optimizer='adam', loss=[vae_loss1, vae_loss2],\n\u001b[1;32m----> 8\u001b[1;33m            experimental_run_tf_function=False)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;31m# Prepare list of loss functions, same size of model outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     self.loss_functions = training_utils.prepare_loss_functions(\n\u001b[1;32m--> 336\u001b[1;33m         self.loss, self.output_names)\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mtarget_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_target_tensor_for_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mprepare_loss_functions\u001b[1;34m(loss, output_names)\u001b[0m\n\u001b[0;32m   1354\u001b[0m       raise ValueError('When passing a list as loss, it should have one entry '\n\u001b[0;32m   1355\u001b[0m                        \u001b[1;34m'per model outputs. The model has {} outputs, but you '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m                        'passed loss={}'.format(len(output_names), loss))\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[0mloss_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When passing a list as loss, it should have one entry per model outputs. The model has 1 outputs, but you passed loss=[<function vae_loss1 at 0x0000018F68A0EDC8>, <function vae_loss2 at 0x0000018F68A0EA68>]"
     ]
    }
   ],
   "source": [
    "# 다중로스써서 동시에 줄이는 것. 또한 함수를 loss에 넘겨주었다.\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss # 리턴값 1개로 만들 수 있다.\n",
    "\n",
    "vae.compile(optimizer='adam', loss=[vae_loss1, vae_loss2],\n",
    "           experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss1(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    return xent_loss\n",
    "\n",
    "def vae_loss2():\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "        0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "        0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "        0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "        0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "        0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "        0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "        0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "        0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "        0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "        0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "        0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "        0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "        0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "        0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "        0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = vae.predict(x_train[0:16].reshape(16, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18f68a01448>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 샘플링하는걸 선형 결합으로 쓸것이다. 이래도 상관없는 이유는 어차피 결과만 좋으면 장땡이긴 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "Conv1 = Conv2D(32, (3, 3), input_shape = (28, 28, 1),\n",
    "               use_bias=False,\n",
    "               kernel_initializer = 'ones')\n",
    "model.add(Conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_initializer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0-GPU",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
