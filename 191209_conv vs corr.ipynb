{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve([3], [1, 2])\n",
    "np.convolve([3, 2], [1, 2]) # flip 하고 곱한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.correlate([3], [1, 2]) # 그냥 곱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.correlate([3, 2], [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 목적은 필터(커널) 찾아내는 것이기 때문에, correlation 방식으로 사용해도 아무 상관 없다. 근데 신호처리하는 사람들은 이걸 아냐 모르느냐 따라서 아주 민감하다.\n",
    "\n",
    "그런데 conv는 2번 연산을 해야 하는 반면, corr는 1번 연산을 해야 하기 때문에 비교적 간단하다. 연산이 한 번 줄어든다. 그래서 corr을 하지만, 부를 때는 conv라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신호처리 컨볼루션 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve, convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 10,  8],\n",
       "       [ 6, 17, 12],\n",
       "       [ 3,  7,  4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve([[1, 2], [1, 1]], [[3, 4], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10, 13, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve([1, 2], [3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 1   3, 4\n",
    "# 2, 1   3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 먼저 열과 행이 다 플립된다.\n",
    " - 왼쪽 것이 하나씩 스트라이드 되면서, element wise방식으로 곱해진다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution filter visualization\n",
    "\n",
    "https://keras.io/examples/conv_filter_visualization/\n",
    "\n",
    "케라스는 불러올 때 tensorflow.keras로 불러와야 한다는 것 명심."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\white\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image as pil_image\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.gen_math_ops.sqrt(x, name=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.backend.mean(x, axis=None, keepdims=False)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.epsilon() # 아주 작은 숫자를 리턴한다. 1.x과 2.x 모두 동일!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"utility function to normalize a tensor.\n",
    "\n",
    "    # Arguments\n",
    "        x: An input tensor.\n",
    "\n",
    "    # Returns\n",
    "        The normalized input tensor.\n",
    "    \"\"\"\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\"utility function to convert a float array into a valid uint8 image.\n",
    "\n",
    "    # Arguments\n",
    "        x: A numpy-array representing the generated image.\n",
    "\n",
    "    # Returns\n",
    "        A processed numpy-array, which could be used in e.g. imshow.\n",
    "    \"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon()) # 표준화 공식하고 똑같다.\n",
    "    x *= 0.25 # 표준편차를 1- > 0.25에 가깝게 한다. 유동변동성을 작게 하기 위해서.\n",
    "\n",
    "    # clip to [0, 1] # 자르는 것\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0)) # 채널퍼스트면 채널라스트 방식으로 바꿈\n",
    "    x = np.clip(x, 0, 255).astype('uint8') # unit로 바꾸는 기법.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(np.array([1, 2, 3, 4, 5]), 1, 2) # 조건에 따라서 잘라준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(x, former):\n",
    "    \"\"\"utility function to convert a valid uint8 image back into a float array.\n",
    "       Reverses `deprocess_image`.\n",
    "\n",
    "    # Arguments\n",
    "        x: A numpy-array, which could be used in e.g. imshow.\n",
    "        former: The former numpy-array.\n",
    "                Need to determine the former mean and variance.\n",
    "\n",
    "    # Returns\n",
    "        A processed numpy-array representing the generated image.\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((2, 0, 1))\n",
    "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_filter_image(input_img,\n",
    "                               layer_output,\n",
    "                               filter_index):\n",
    "        \"\"\"Generates image for one particular filter.\n",
    "\n",
    "        # Arguments\n",
    "            input_img: The input-image Tensor.\n",
    "            layer_output: The output-image Tensor.\n",
    "            filter_index: The to be processed filter number.\n",
    "                          Assumed to be valid.\n",
    "\n",
    "        #Returns\n",
    "            Either None if no image could be generated.\n",
    "            or a tuple of the image (array) itself and the last loss.\n",
    "        \"\"\"\n",
    "#         s_time = time.time() # 시간측정 용도\n",
    "\n",
    "        # we build a loss function that maximizes the activation\n",
    "        # of the nth filter of the layer considered\n",
    "#         if K.image_data_format() == 'channels_first':\n",
    "#             loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "#         else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # we compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, input_img)[0] # 옛날방식으로 미분계산\n",
    "\n",
    "        # normalization trick: we normalize the gradient\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([input_img], [loss, grads]) # 2.0의 Gradient Tape\n",
    "\n",
    "        # we start from a gray image with some random noise\n",
    "        intermediate_dim = tuple(\n",
    "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random(\n",
    "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
    "        else:\n",
    "            input_img_data = np.random.random(\n",
    "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # Slowly upscaling towards the original size prevents\n",
    "        # a dominating high-frequency of the to visualized structure\n",
    "        # as it would occur if we directly compute the 412d-image.\n",
    "        # Behaves as a better starting point for each following dimension\n",
    "        # and therefore avoids poor local minima\n",
    "        for up in reversed(range(upscaling_steps)):\n",
    "            # we run gradient ascent for e.g. 20 steps\n",
    "            for _ in range(epochs):\n",
    "                loss_value, grads_value = iterate([input_img_data])\n",
    "                input_img_data += grads_value * step\n",
    "\n",
    "                # some filters get stuck to 0, we can skip them\n",
    "                if loss_value <= K.epsilon():\n",
    "                    return None\n",
    "\n",
    "            # Calculate upscaled dimension\n",
    "            intermediate_dim = tuple(\n",
    "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
    "            # Upscale\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
    "                                                           pil_image.BICUBIC))\n",
    "            input_img_data = np.expand_dims(\n",
    "                process_image(img, input_img_data[0]), 0)\n",
    "\n",
    "        # decode the resulting input image\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "#         e_time = time.time() # end time. 시간 측정용\n",
    "        print('Costs of filter {:3}: {:5.0f}'.format(filter_index,\n",
    "                                                                  loss_value))\n",
    "        return img, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 예시\n",
    "x = tf.ones((2, 2))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.multiply(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can not convert a function into a Tensor or Operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e436a5500306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# tf.keras.backend.function()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   3780\u001b[0m                'backend') % key\n\u001b[0;32m   3781\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3782\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mGraphExecutionFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[0;32m   3432\u001b[0m     \u001b[1;31m# dependencies in call.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3433\u001b[0m     \u001b[1;31m# Index 0 = total loss or model output for `predict`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3434\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3435\u001b[0m       \u001b[0mupdates_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3436\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[1;34m(control_inputs)\u001b[0m\n\u001b[0;32m   5255\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5256\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[1;34m(self, control_inputs)\u001b[0m\n\u001b[0;32m   4689\u001b[0m           (hasattr(c, \"_handle\") and hasattr(c, \"op\"))):\n\u001b[0;32m   4690\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4691\u001b[1;33m       \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4692\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4693\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3610\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3612\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3697\u001b[0m       \u001b[1;31m# We give up!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3698\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[1;32m-> 3699\u001b[1;33m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   3700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3701\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a function into a Tensor or Operation."
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3])\n",
    "b = tf.keras.backend.function([a], [np.mean])\n",
    "# tf.keras.backend.function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = next(reversed([3, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tensorspace.org/\n",
    "\n",
    "convolution할때 아주 기똥차다. playground들어가면 아주 좋은거 많다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\white\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__func__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.layers)\n",
    "dir(model.get_layer) #name을 지정할 수 있다. 특정 레이어를 뽑을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그냥 바로 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg = vgg16.VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MapFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute filters 0 to 256\n",
      "Costs of filter   0:  1064 ( 6.28s )\n",
      "Costs of filter   1:  3045 ( 1.30s )\n",
      "Costs of filter   2:  1344 ( 1.40s )\n",
      "Costs of filter   3:  3989 ( 1.29s )\n",
      "Costs of filter   4:   761 ( 1.37s )\n",
      "Costs of filter   5:  3284 ( 1.57s )\n",
      "Costs of filter   6:  1044 ( 1.31s )\n",
      "Costs of filter   7:  1634 ( 1.33s )\n",
      "Costs of filter   8:  1619 ( 1.41s )\n",
      "Costs of filter   9:  3113 ( 1.41s )\n",
      "Costs of filter  10:   969 ( 1.40s )\n",
      "Costs of filter  11:  2909 ( 1.44s )\n",
      "Costs of filter  12:  1568 ( 1.31s )\n",
      "Costs of filter  13:  1062 ( 1.47s )\n",
      "Costs of filter  14:  1211 ( 1.41s )\n",
      "Costs of filter  15:   888 ( 1.54s )\n",
      "Costs of filter  16:  1323 ( 1.37s )\n",
      "Costs of filter  17:   722 ( 1.34s )\n",
      "Costs of filter  18:  2603 ( 1.52s )\n",
      "Costs of filter  19:  1779 ( 1.35s )\n",
      "Costs of filter  20:  1053 ( 1.46s )\n",
      "Costs of filter  21:  2801 ( 1.51s )\n",
      "Costs of filter  22:  1103 ( 1.52s )\n",
      "Costs of filter  23:  2937 ( 1.45s )\n",
      "Costs of filter  24:   936 ( 1.35s )\n",
      "Costs of filter  25:  1342 ( 1.40s )\n",
      "Costs of filter  26:  1110 ( 1.41s )\n",
      "Costs of filter  27:   987 ( 1.59s )\n",
      "Costs of filter  28:  1847 ( 1.40s )\n",
      "Costs of filter  29:   772 ( 1.61s )\n",
      "Costs of filter  30:  1186 ( 1.48s )\n",
      "Costs of filter  31:  2145 ( 1.44s )\n",
      "Costs of filter  32:  6262 ( 1.53s )\n",
      "Costs of filter  33:  1811 ( 1.53s )\n",
      "Costs of filter  34:   730 ( 1.38s )\n",
      "Costs of filter  35:   891 ( 1.52s )\n",
      "Costs of filter  36:   754 ( 1.38s )\n",
      "Costs of filter  37:  2499 ( 1.39s )\n",
      "Costs of filter  38:  4202 ( 1.38s )\n",
      "Costs of filter  39:   906 ( 1.51s )\n",
      "Costs of filter  40:  1171 ( 1.39s )\n",
      "Costs of filter  41:  1011 ( 1.42s )\n",
      "Costs of filter  42:   914 ( 1.40s )\n",
      "Costs of filter  43:  2313 ( 1.59s )\n",
      "Costs of filter  44:  1874 ( 1.51s )\n",
      "Costs of filter  45:  1054 ( 1.57s )\n",
      "Costs of filter  46:  2153 ( 1.56s )\n",
      "Costs of filter  47:  1710 ( 1.58s )\n",
      "Costs of filter  48:   904 ( 1.49s )\n",
      "Costs of filter  49:   863 ( 1.58s )\n",
      "Costs of filter  50:   798 ( 1.51s )\n",
      "Costs of filter  51:   908 ( 1.55s )\n",
      "Costs of filter  52:   737 ( 1.51s )\n",
      "Costs of filter  53:  1191 ( 1.60s )\n",
      "Costs of filter  54:  1518 ( 1.41s )\n",
      "Costs of filter  55:   851 ( 1.52s )\n",
      "Costs of filter  56:  1403 ( 1.49s )\n",
      "Costs of filter  57:  1015 ( 1.41s )\n",
      "Costs of filter  58:  2079 ( 1.42s )\n",
      "Costs of filter  59:  1561 ( 1.42s )\n",
      "Costs of filter  60:  5069 ( 1.65s )\n",
      "Costs of filter  61:  3976 ( 1.74s )\n",
      "Costs of filter  62:  1054 ( 1.62s )\n",
      "Costs of filter  63:   894 ( 1.49s )\n",
      "Costs of filter  64:  2663 ( 1.46s )\n",
      "Costs of filter  65:   761 ( 1.49s )\n",
      "Costs of filter  66:  2389 ( 1.54s )\n",
      "Costs of filter  67:   469 ( 1.44s )\n",
      "Costs of filter  68:   182 ( 1.62s )\n",
      "Costs of filter  69:  1043 ( 1.44s )\n",
      "Costs of filter  70:   740 ( 1.70s )\n",
      "Costs of filter  71:  1440 ( 1.47s )\n",
      "Costs of filter  72:  2813 ( 1.45s )\n",
      "Costs of filter  73:  1301 ( 1.53s )\n",
      "Costs of filter  74:  1182 ( 1.65s )\n",
      "Costs of filter  75:  1489 ( 1.64s )\n",
      "Costs of filter  76:   753 ( 1.62s )\n",
      "Costs of filter  77:  1129 ( 1.64s )\n",
      "Costs of filter  78:   814 ( 1.56s )\n",
      "Costs of filter  79:  4778 ( 1.77s )\n",
      "Costs of filter  80:   956 ( 1.47s )\n",
      "Costs of filter  81:  1497 ( 1.56s )\n",
      "Costs of filter  82:   826 ( 1.57s )\n",
      "Costs of filter  84:  1619 ( 1.62s )\n",
      "Costs of filter  85:  2167 ( 1.66s )\n",
      "Costs of filter  86:  1187 ( 1.67s )\n",
      "Costs of filter  87:  2566 ( 1.51s )\n",
      "Costs of filter  88:   855 ( 1.54s )\n",
      "Costs of filter  90:  1055 ( 1.51s )\n",
      "Costs of filter  91:  1086 ( 1.58s )\n",
      "Costs of filter  92:  1140 ( 1.74s )\n",
      "Costs of filter  93:  2629 ( 1.57s )\n",
      "Costs of filter  94:   593 ( 1.63s )\n",
      "Costs of filter  95:  1965 ( 1.69s )\n",
      "Costs of filter  96:  1050 ( 1.74s )\n",
      "Costs of filter  97:  3899 ( 1.71s )\n",
      "Costs of filter  98:  1248 ( 1.72s )\n",
      "Costs of filter  99:  1073 ( 1.75s )\n",
      "Costs of filter 100:  1147 ( 1.53s )\n",
      "Costs of filter 101:  1062 ( 1.54s )\n",
      "Costs of filter 102:  1193 ( 1.57s )\n",
      "Costs of filter 104:  1097 ( 1.87s )\n",
      "Costs of filter 105:  1462 ( 1.59s )\n",
      "Costs of filter 106:   717 ( 1.64s )\n",
      "Costs of filter 107:   566 ( 1.56s )\n",
      "Costs of filter 108:  1136 ( 1.70s )\n",
      "Costs of filter 109:  1028 ( 1.55s )\n",
      "Costs of filter 110:  1381 ( 1.55s )\n",
      "Costs of filter 111:  1010 ( 1.61s )\n",
      "Costs of filter 112:  1353 ( 1.58s )\n",
      "Costs of filter 113:  3169 ( 1.70s )\n",
      "Costs of filter 114:   942 ( 1.83s )\n",
      "Costs of filter 115:   850 ( 1.78s )\n",
      "Costs of filter 116:   835 ( 1.71s )\n",
      "Costs of filter 117:  1746 ( 1.81s )\n",
      "Costs of filter 118:  2622 ( 1.64s )\n",
      "Costs of filter 119:  1213 ( 1.64s )\n",
      "Costs of filter 120:  1085 ( 1.69s )\n",
      "Costs of filter 121:  1381 ( 1.75s )\n",
      "Costs of filter 122:  2244 ( 1.90s )\n",
      "Costs of filter 123:  1374 ( 1.73s )\n",
      "Costs of filter 124:  2074 ( 1.81s )\n",
      "Costs of filter 125:  1087 ( 1.75s )\n",
      "Costs of filter 126:  1252 ( 1.76s )\n",
      "Costs of filter 127:  1228 ( 1.78s )\n",
      "Costs of filter 128:  4001 ( 1.75s )\n",
      "Costs of filter 130:  1154 ( 1.67s )\n",
      "Costs of filter 131:  1176 ( 1.69s )\n",
      "Costs of filter 132:   651 ( 1.62s )\n",
      "Costs of filter 134:  1314 ( 1.76s )\n",
      "Costs of filter 135:  1423 ( 1.62s )\n",
      "Costs of filter 136:  2895 ( 1.73s )\n",
      "Costs of filter 137:   888 ( 1.72s )\n",
      "Costs of filter 138:  1123 ( 1.65s )\n",
      "Costs of filter 139:  1118 ( 1.69s )\n",
      "Costs of filter 140:   959 ( 1.82s )\n",
      "Costs of filter 141:  2766 ( 1.79s )\n",
      "Costs of filter 142:  1439 ( 1.80s )\n",
      "Costs of filter 143:   886 ( 1.91s )\n",
      "Costs of filter 145:  1118 ( 1.97s )\n",
      "Costs of filter 146:   749 ( 1.81s )\n",
      "Costs of filter 147:   803 ( 1.70s )\n",
      "Costs of filter 148:  2395 ( 1.74s )\n",
      "Costs of filter 149:  2231 ( 1.78s )\n",
      "Costs of filter 150:  1419 ( 1.67s )\n",
      "Costs of filter 151:   917 ( 1.68s )\n",
      "Costs of filter 152:  2041 ( 1.77s )\n",
      "Costs of filter 153:  3682 ( 1.81s )\n",
      "Costs of filter 154:  1744 ( 1.87s )\n",
      "Costs of filter 155:   920 ( 1.89s )\n",
      "Costs of filter 156:  1130 ( 1.67s )\n",
      "Costs of filter 157:   927 ( 1.68s )\n",
      "Costs of filter 158:   866 ( 1.88s )\n",
      "Costs of filter 159:  1501 ( 1.79s )\n",
      "Costs of filter 160:  1499 ( 1.76s )\n",
      "Costs of filter 161:  3205 ( 1.68s )\n",
      "Costs of filter 162:   856 ( 1.77s )\n",
      "Costs of filter 163:  1248 ( 1.98s )\n",
      "Costs of filter 164:   483 ( 1.87s )\n",
      "Costs of filter 165:  1488 ( 1.87s )\n",
      "Costs of filter 166:  1859 ( 1.84s )\n",
      "Costs of filter 167:   916 ( 1.89s )\n",
      "Costs of filter 168:  1033 ( 1.71s )\n",
      "Costs of filter 169:  1134 ( 1.75s )\n",
      "Costs of filter 170:  1139 ( 1.76s )\n",
      "Costs of filter 171:  1735 ( 2.00s )\n",
      "Costs of filter 172:   777 ( 2.02s )\n",
      "Costs of filter 174:  1168 ( 1.79s )\n",
      "Costs of filter 175:  1026 ( 1.88s )\n",
      "Costs of filter 176:  1412 ( 1.94s )\n",
      "Costs of filter 177:  2990 ( 1.87s )\n",
      "Costs of filter 178:  1652 ( 1.84s )\n",
      "Costs of filter 179:  1176 ( 1.73s )\n",
      "Costs of filter 180:  1193 ( 2.06s )\n",
      "Costs of filter 181:  1495 ( 1.90s )\n",
      "Costs of filter 182:  1366 ( 1.80s )\n",
      "Costs of filter 183:  2072 ( 1.76s )\n",
      "Costs of filter 184:   785 ( 1.77s )\n",
      "Costs of filter 185:   978 ( 1.77s )\n",
      "Costs of filter 186:   895 ( 1.92s )\n",
      "Costs of filter 187:  1428 ( 1.76s )\n",
      "Costs of filter 188:  1148 ( 1.79s )\n",
      "Costs of filter 189:  1837 ( 1.97s )\n",
      "Costs of filter 190:   963 ( 2.00s )\n",
      "Costs of filter 191:   822 ( 2.01s )\n",
      "Costs of filter 192:   789 ( 1.77s )\n",
      "Costs of filter 193:   878 ( 2.08s )\n",
      "Costs of filter 194:  1462 ( 2.05s )\n",
      "Costs of filter 195:   647 ( 1.98s )\n",
      "Costs of filter 196:  1472 ( 2.04s )\n",
      "Costs of filter 197:  1152 ( 2.07s )\n",
      "Costs of filter 198:  1418 ( 1.99s )\n",
      "Costs of filter 199:  2054 ( 1.99s )\n",
      "Costs of filter 200:  1308 ( 1.97s )\n",
      "Costs of filter 201:   966 ( 2.00s )\n",
      "Costs of filter 202:  1012 ( 2.13s )\n",
      "Costs of filter 203:  3999 ( 1.92s )\n",
      "Costs of filter 204:   705 ( 1.88s )\n",
      "Costs of filter 205:  1168 ( 1.81s )\n",
      "Costs of filter 206:   669 ( 2.09s )\n",
      "Costs of filter 208:  1443 ( 1.90s )\n",
      "Costs of filter 209:  1411 ( 1.83s )\n",
      "Costs of filter 210:  1114 ( 1.91s )\n",
      "Costs of filter 211:   987 ( 1.98s )\n",
      "Costs of filter 212:  1080 ( 2.04s )\n",
      "Costs of filter 213:  1865 ( 2.10s )\n",
      "Costs of filter 214:  1468 ( 1.97s )\n",
      "Costs of filter 215:  1116 ( 2.05s )\n",
      "Costs of filter 216:  1354 ( 2.06s )\n",
      "Costs of filter 217:  1087 ( 1.97s )\n",
      "Costs of filter 218:   583 ( 1.86s )\n",
      "Costs of filter 219:  1460 ( 2.12s )\n",
      "Costs of filter 220:  3161 ( 1.99s )\n",
      "Costs of filter 221:  1481 ( 2.06s )\n",
      "Costs of filter 222:  1196 ( 2.11s )\n",
      "Costs of filter 223:  1480 ( 2.04s )\n",
      "Costs of filter 224:  1145 ( 2.20s )\n",
      "Costs of filter 225:   746 ( 1.94s )\n",
      "Costs of filter 226:   833 ( 1.96s )\n",
      "Costs of filter 227:   875 ( 2.03s )\n",
      "Costs of filter 228:  2575 ( 2.06s )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 229:  1213 ( 2.09s )\n",
      "Costs of filter 230:  2739 ( 1.99s )\n",
      "Costs of filter 231:   934 ( 2.10s )\n",
      "Costs of filter 232:  1076 ( 2.05s )\n",
      "Costs of filter 233:  1486 ( 2.13s )\n",
      "Costs of filter 234:  1740 ( 2.11s )\n",
      "Costs of filter 235:  1310 ( 1.96s )\n",
      "Costs of filter 236:  2363 ( 2.09s )\n",
      "Costs of filter 237:  2676 ( 2.12s )\n",
      "Costs of filter 238:  1411 ( 1.96s )\n",
      "Costs of filter 239:  1589 ( 1.99s )\n",
      "Costs of filter 240:  1500 ( 2.07s )\n",
      "Costs of filter 241:   476 ( 2.00s )\n",
      "Costs of filter 242:  1282 ( 2.15s )\n",
      "Costs of filter 243:   359 ( 2.05s )\n",
      "Costs of filter 244:  1094 ( 1.95s )\n",
      "Costs of filter 245:  1276 ( 2.05s )\n",
      "Costs of filter 246:  1349 ( 2.04s )\n",
      "Costs of filter 247:  1272 ( 1.96s )\n",
      "Costs of filter 248:   248 ( 2.13s )\n",
      "Costs of filter 249:  1572 ( 2.17s )\n",
      "Costs of filter 250:  1050 ( 2.04s )\n",
      "Costs of filter 251:  1333 ( 1.95s )\n",
      "Costs of filter 252:  1229 ( 1.96s )\n",
      "Costs of filter 253:   793 ( 2.02s )\n",
      "Costs of filter 254:  2551 ( 2.00s )\n",
      "247 filter processed.\n"
     ]
    }
   ],
   "source": [
    "MapFilter.visualize_layer(vgg, 'block3_conv3')\n",
    "# visualize_layer(vgg, 'block3_conv3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer 4가지 전략\n",
    "\n",
    "내일!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 남이 만든 모델 쓰는 법\n",
    "\n",
    "1. 텐서플로상에서 가져오는 방법 (2.x): 텐서허브에서 가져온다. 텐서허브는 사람들이 모델 모아두는 곳이다.\n",
    "2. 케라스에서 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.keras.applications' from 'C:\\\\Users\\\\white\\\\Anaconda3\\\\envs\\\\tf2.0-gpu\\\\lib\\\\site-packages\\\\tensorflow_core\\\\python\\\\keras\\\\api\\\\_v2\\\\keras\\\\applications\\\\__init__.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.applications # 남이 만들어둔 모델 가져다 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.vgg16.VGG16() # weight, include_top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0-GPU",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
