{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "텐서로 이미지를 무식하게 불러오는 방법은 텐서로 관리할 수 있고, 속도가 빠르다. 보통은 데이터 불러오는 건 딱 한번 만들지만, 만들기가 어렵다. 현재 우리는 가지고 있는 데이터만 처리한다고 생각하는데, 나중에 들어오는 데이터도 생각해야 한다. image data generator는 축복이다. 이 비슷한게 파이토치에도 있고, 다른데도 있는데 정말 좋다. 그래서 케라스하고 파이토치하고 서로 배껴가기도 한다. \n",
    "\n",
    "이미지 데이터를 불러오고 -> 모델을 구성한다 (케라스, 텐서플로 2가지 방법)\n",
    "\n",
    " - 텐서플로 이용: 생으로 하는게 너무 귀찮으니, 에스티메이터라는 것을 지원했다. 그런데 이건 케라스로 대신할 수 있다. 홈페이지에서 에스티메이터 보다는 케라스로 하는 것을 추천한다. 에스티메이터는 말은 쉽지 아주 복잡한 구조다. 더이상 안쓰니.. 에스티메이터는 버려라.\n",
    " - 케라스 이용: 쉽고 편~~~~~~~하다 ^^\n",
    " \n",
    "텐서플로 2.0은 비정형데이터에 최적화 되어있다. 근데 1.0대에서는 정형데이터에 쓰는 예시들이 별로 없다. 판다스하고 텐서플로를 연동할 수 있는데, 이렇게 하면 파이프라인을 구성해서 전처리같은것을 한번에 할 수 있다. 그런데 이걸 시용하면 판다스하고 바로 붙어버려서, 아주 효울적으로 쓸 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷 DNN\n",
    "\n",
    "옵션을 엄청 많이 넣을 수 있다. 그래서 에스티메이터 쓰느니, 이걸 많이 썼다고 한다. 그래서 에스티메이터가 뭐냐? 자주 만드는 애들을 추상화 시켜서, 하이레벨 기법으로 만드는 애를 에스티메이터라고 한다. fit 대신 train을 넣고, 데이터를 바로 넣는 대신 데이터 인풋 함수를 넣는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPClassifier() # shitf tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스로 딥러닝 모델 짜는 방법\n",
    "\n",
    " - sequencial\n",
    " - Model 이용\n",
    " - Model을 이용한 상속\n",
    " \n",
    "그런데 sequencial을 이용한 것은 멀티 인풋, 멀티 아웃풋이 안된다. 그래서 RNN같은 경우는 sequencial로 만들 수 없는 것이다.\n",
    "\n",
    "eager tensor라는 것을 써서, 바로바로 결과값을 확인할 수 있다.\n",
    "\n",
    "뉴럴네트워크는 Gradient descent를 써서 학습한다. 러닝 레이트를 어떻게 하는가, 그레디언트를 어떻게 하는가에 따라서 학습이 달라진다. 학습을 시키는데 fit에 에폭도 넣고, 밸리데이션도 넣을 수 있다. callback도 있고 등 많은 옵션이 있는데, 알렉스넷의 경우 젤 처음에 몇번 에폭 돌다가 러닝레이트를 바꿀 수 있다. 그런데 이건 우린 못한다. 단계마다 하이퍼파라미터를 조절 못하는 것이다. 이걸 할 수 있는게 train_on_batch이다.\n",
    "\n",
    "이 학습시키는 방법도 오버피팅에 관련된 것이기 때문에 잘 배워야 하는데, 에폭을 많이 돌릴 수록 오버피팅이 발생시키기 때문이다. 그래서 단계별로 학습시키는 기법이 필요하다. \n",
    "\n",
    "### 백프로파게이션의 미분\n",
    "\n",
    "컴퓨터는 미분을 할 때, 리미트 0으로 수렴하는 것을 아주 작은 값으로 표현한다. 이것을 computational differenciation이라고 한다. 텐서플로에도 당연히 있다. \n",
    "\n",
    "autograd라고도 한다. 이 개념만 잘 알고 있으면, 파이토치에도 적용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래디언트 테이프\n",
    "\n",
    "https://www.tensorflow.org/tutorials/customization/autodiff\n",
    "\n",
    "자동미분이라는 것은 벡터값 중에 0이 되는 값을 찾는 것이다. 로스 펑션이 만들어졌다는 가정 하에, n 차원 벡터에서 미분을 계산한다. 자동미분을 해두면 지가 알아서 다 계산해준다. 쓰기는 쉬운데 복잡하다.\n",
    "\n",
    "다시 말하지만, loss function이 있다는 가정 하에 최적화하는 것이다. 텐서프로 2.0에서는 백프로파게이션 하면서 각 노드마다 미분값을 저장해둔다. 그 구하는 각각을 저장해둔 공간을 그레디언트 테이프라고 생각하면 된다. ★★★ 카세트 테이프라는 것이 있는데, 여기에도 데이터를 저장해둘 수 있었지? 그거 생각하면 된다. 그래디언트를 기록해두는 저장매체라고 이해하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxMSEhUSEhIVFRUWFRUXFRcYFRcXFhcWGBUWFxYXFxcYHSggGBolGxUVITEhJSkrLi4uFx8zODMtNygtLisBCgoKDg0OFxAQGy0mHx8tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLf/AABEIAMUA/wMBIgACEQEDEQH/xAAcAAABBQEBAQAAAAAAAAAAAAACAAEDBAUGBwj/xABAEAABAwIDBQYEBAQFAwUAAAABAAIRAyEEEjEFQVFhgQYTInGRoTJCscFi0eHwB1JykhQjM4LxstLiFjRDosL/xAAYAQEBAQEBAAAAAAAAAAAAAAAAAQIDBP/EACERAQEAAgMBAAIDAQAAAAAAAAABAhEDEjEhE0EEUdFh/9oADAMBAAIRAxEAPwD2djCDJ0RVTm0unNTNbiqVbaLKTi0yTaYHXf5qyW+C7TcGiDZR5DM7pnosyttppMhh6kIXbcdEBg0i5JWvx5J2jZqOzCBdNSOXWywBtWpuyjp+ajqbRqu1d7AfZX8VTtHQPYSZAspalQEEArlziXn53f3FRG+q1+L/AKnZ01Ou1s5nNHUKHEY+nPxjpJXPQnAVnFDs33bXpgRc2jTlzVZm2GgyGk9QFkwlCv48U7V04qCoA5lx9OSmY8AQdVz2zcaaTuLTqPuOa3gzP4gbHRccsetbl2GmwgydEdU5tLpzUzW4pgMnOVlT0nBog2QZDMxaZ6IizNdP3ny9PsgVR2YQLpUjl1smDct9UiM/KEAvYSZAspKjwRA1TCrltwTCnlvwQKl4dbJqjZMi4Tk5+UJw/LbVA+cRG+I6oKQymTZP3fzdfukXZrab0CqjNpdEx4Ag6oQcltZS7vNfigGmwgydEdU5tLpjUzW4pAZOcoCpuDRBsVEaZ4IyzNfRP30WjSyB3Uw0SNy5vbX+t/UwHqCQfaF0DJm8xz0WP2paB3TxFnEGOBE/YrWF1UvjLARAJwEQC9TkgxNNxaQxwY7c4tzR/tkSnwtNzWgPfndvdlDfYaK02g46Nd6FG3Cu4e4H3U2rEZisQazgaIZSbYOccz3niAwkNb5meQVh2MIIaGFzidGzYby6RAHXyWv/AIF28gep+gRDBfi9B+ZCm4KcKJ9dgOUvaHHQFwBvpZa7cA0ak/T7GFSxeDa158IMwQYEkDSTxBlO0EUJQjhNCqBIV7ZuPLPCT4TpyP5KnCYhSyWLK6h1MASEzPFruWXsrGXDHm26dPIrVq/h9v0Xmymrp0l2F7spgIu7EZt+vXVKnEeLXnr7oLzviekfkop2OzWKd5y6J6sR4deX6JqX4vf9UBNpg3O9A2oXWOhTPmbTHLRSPiLRPLVAL/DpvTsbmuUNL8XSf1SqTPhmOWnsgXeGcu6Y6aInty3Ce0bpjrP5oKcz4tOenugdgzXO5M6oRYbkqv4fb9EbIi8Tz1QM6mGiRqEzDm13IaczeY56Iqv4esfogZ7stgjFIG/FNTiPFE89fdRuzbp90EjqgdYb1jdpS1tINcfE5wyDy18rFbJp5b8Fi9p2F9IO/kcCfI2PvCs9D9ni19MgtaXNMSRJg6K+6RP+Xw3kD2lctgKxaYBIkbjCvFxOpJ6rrMdsVsiq0G4A9PqY3j6Jn41okAwNNQZ9isYBPCvSJtqPxVLdM8co/RQvxg3Bx8z/AMqlCq7Qwz6jcrKpp8SACSOAJ+HzF1ZjIm2m/HGLN0mL+drRxUVTEueBmERu3jdrJ4LGZRq0hAFRwAtlqd4baT3pkn181c2e6qQTVa1s/C0GXAfjI8M+VldQWEkUJQqgU0I4ShBGQtjZWNnwu+KPUfmsotTCQZGqmWO4sunRvbmMhF3gjLv066KpgsbmbEXGv5jkrXd/N1+689mnUzW5blO8ZtNyQfmtokTksLyoHbUDbHchbTLbnciFPNfihFTNbigd5zabuKdj8timIyaXlIMzX0QN3ZnNu16aonuzWCHvPl6fZOW5b9ECYcuu/gmdTJuN6cDPc2hMamW3BATqgdYb0zPDrvSNPLfgkDn1tCBnNzXCMVgLXshL8tk/czedUAMcSYOij2nhw6m5g+YEddR7wrFR4IgaoaQy62QcKy3mFerYkMaHEOMkCGtLjc8tBzNgm2tRDazwNCcw63+sosE60cF2xrGUS0KmafC5sGCHCOGkEgi+oKlhOAihdGQQnARQnhEDCUI4ShFBCjq0s28jyMKeEoQQUKOURmc65u4yb7p4KSEcKDG0qjmOFJ4Y8jwuczOB/tkSiJMqbKudbhHNd/nsqufurB7ntP8ASWQaR5ZW8pWns5uID/FejBvUtVB3RlsW/wBUHzRWhTcWkEaj9wtjD4nPEaTBHDksDEbQos+Kqwcswn01VIdrsPSMteXbiGtNx5mAs54bhMtO0qiBIsmpX1uquysYyrTbWYZY4WO8HeCNxBkKzVGbS687qZ7yDA0UlRoAkapMeAIJuo2MIMnRA9I5tbpVXQYFk9U5tLp6bg0QbIHyiJ3xPVBSMmDdNkMzumeiOq7MIF0A1Tl0sjY0ESdU1I5dbIHsJMjRAqbyTB0RVfDpZFUeCIGqGkMutkD0gCJNyo3VDOqKo3MZFwpBUAtKAO7y3nRKc/KEzahNjvT1Bl0QYnaTDwGu3gwfI3HuPdZGGdDh6LrMXh+9puB1IMeYuPdcg1alRsAIgFk1+0FCl4alSHQLZXE+wVGr23w4+FtR3QAe5n2Xon1zdLlThq4yt26PyUAP6nk+wA+qoVu2WJdoWM/pZ/3SrpHoeVZ+D2xRe1xJLHMBNRri1pYRq0mdxGui8+r7ZxNT4q1Toco9GwqTqZdM3nWblTSzbtuz/bClWbUNYinlqODDch9KTkcNfFFiOI3SrVbtZhm6F7v6WH/9QvOqWGyFxLrG8RYHeZJ32VbFbVos+dp8jP0U3IvWvQK3bVnyUXH+pwb9AVRrdsqx+FlNvRzj7mPZedVO0QJhs3nQcBO9U37ccTcOjf4vspc4vR6FiO0mJOtYt8srfoAqBxVSqYzVKp4DPUPoJVPZnaylTpCkKNNz8hbnytDpzEhx8EuIEWJ+VWK/bDE0m1HsyANc1pGQH431KgALpsO8cPJT8i9Yz6u1WN3OPSFTqbbO5nqVnd5n8R1JKy24eqSC50aWzfkpc6vWPbP4O7QfWGJpuMNb3TgNwJzhx6hrfRekg5Ocrw/+E/aJuGxLqLh/7jI0OkeFwLstjqDmj0XuDBm13Lnl7tSNLNedUu8zWiJTOqEGBuRuphokblkCBk5ykWZr6JUzm13Jnvy2CB+8+WOX2SDct9dyLuxGbfE9dUDHZrFA5Ge+kJd5ltGiVQ5dETaYIkoB7vLeZhInPyhMyoXGDvT1PDogQfltql3M3nVOxuYSUBrEWQSPIi0Ty1Q0vxe6ZtMtudydxzabuKBqgM+HTkuY2rQyVTGhgjrr7yupa/LYrH7QYc5W1OcdDcfvmrB592yw0hrwLgerZH0JH9x4LlmNK7/bmAdXp5KYJqSCwAgGdDrb4XOWTjO0mzMEe5qYGq+uwAVA4hzM4EOgueREzoIXacmox13XMvDhoJMjwi5Im8DU2v0Q7Ux7aLZsXaBvPnwC23fxdyCMLgaFIbpM+zA1eeYhzqtR9UgS97nnLpLnEmOUlZvJa1MdNjZ+NxFd4a11Js8QQOpuuiOxKjqNXPiaNPKbloeXuHBpLob0C5zY/hcCaQd5tXYYTaLGgkUGA8cgn1hZvjePrz7GYOLNLnDe52/81Sr0V1W03d44kkfX6KthtlGoQ1mWXGAHG5OsBok7lZjazbHK1KBsrlDDngtraOzf8PUy1S4VABZrdxEi5InXmgpYqgD/AJneAQTMhxtuiLT5rpeLKY7cvyY70oswh1Gqu43Dk025sQ4nu3vqNMtbAqANDYs4mxjdCsO2vhw2adCq8jUvIa0f2krJ2ttY1gG92xgB+UGepOq56b2go4mGkQDBj4r3FrdCp31BFyJI3LLa2DIR16mWBy+5V18JRGqRUzNMEGWkbuC+n+ztd9TCYao4lznUKTnHi4sBJPNfNOxtk1MT3r2FjW0mZnOqPaxpPysaXavdBgcty927P9scNQwWHaS5zxQohzWtPhcKbQWkugSDIsVLLZ8Nu2YRF4nmo6YM3mOa8/2h/EB5J7qi1vN5Lj6CFzu1u0WKxAyvxFRreFN3ddJZBI6qzhyO8eubRx9KkJfVYzzcB7b1l7U7V4fD0mVJ73OTlFMtcTYmTJsLR5ryJ54mTzufXUpmYgNM2J4ESOo1XScM/dTs9Z2H2toYkgSab5+CpA37iDBXRVYjw68l8/0zM+MyTI0BE3gRu4b16J/D/tBE0cRWL5gUiWkRxa52gOkAm94Wc+LU3FmTvKX4vdA8GbTHLRE4ZtN3FO2oG2O5cGj1CItE8tUNK3xe6ZtMtudydxzabuKBqgM205KQEReELX5bFCaJN7XQIVM1uKdwyaXlFUaAJGqGlf4kCDM1yoMY3Ox1ONRA8xp7gKaoSDbRHlETviesIOOoVgypTcf52j1I/fVeafxY2e47RqGkGuzhp108DQ7Q6yfcL0btTh4ZWF9C9sa28QjqIXg+O2jVf8T3QJgaC+th5D0W5NpvSwzYzhd72M83gFQYP/D3OWpaCGueBJ3yQ2SPKNVn5ZUjKaujbpcLX70ZWUqVNvEST/cZPutPD7Nki8+pXE4Wu+mZY6D5Aj0IhWK20K77OrVCOGYgegstSxLt2tajSp3quLGj+nN0a4gnottmI2NQhz8WK0jxNFNzpggtILB4SCOO8ry2jsyq67aTzO/KfqrlPs7WOrQ3zcPtKtu006za/avZuR7KOHe8mcpcxtNovInK7M6PIExzK4sOz21netXB9kX1DAdJ3ho+5K1x2OqYZhrzGUb3AnxeGwAj5uK1hhlr54xlnjL9v1yLcM7h6p+45+i1K4EjMLfREzDAK9F2x34ci8EjfAkjpv8AVWcHhA4Zi2+gkbuvmtt2Hb8skQNbXi9hoJUlOitfjOzOp4G+i3KDgGhRtpqzTDW+JwJAu6IzZd8TyWpNJUFfFBtzA8/1hUam1qY1qAev6JYfYlbaFQ900GBMEw2mCTAcYv7kwYW1W7A08PTz4nF5B+FsCeAk3191i5X9LJGTQxtB3/yT52H5K+xrYtEctFof+ie9pZqGIDxAy5miJFxJOYbzu3rknYKthXuzhzHNIlh0c0zJbcyBu1BvorMtemmvUwrdzRzlxE+iVLGPpOk+Hh4g4+Thw81YYMwDo3J3EgQMvVocta/pNu57K9s9KdXp/wCJ3+Xou6o5ajQ8GQeGi8AbSrzm7uQdzQAPMAb11PZvtXUoHK4mN8z/APYffXzXPLjmX2etTLT1cVM1jvTuGTTeqez9pU6zM1MiYmN/mOI5q5SvqvNZZ8rodrM1yhNYi0aJVCQbaKRrAoImMIMnRFVObS6Xe5rREpRk5z0QPTdlEFBkMzumeiLJmvol3nyxy+yDK7RU2lofvHhPlc/X6rwvGdlWiq8F8APcAAN0mLzwXv8AtLCzScNTFvMXH0Xk+22xWdzg+oH3XTBK51vZ+mwS1hqOkWc/KPUBb2ztjS0RhxNgYaXNnhmIR7N26yhma6mXOzte0gTaGiJ11aVcqdrqzg7JRDZcHeIyN3kd3BaER7Dte4vdQYDIBl0CSdcrbLTodkqdObsZlIBysA1i89Vh4jbOLeTmrZQdQANeNgFQr1yf9Ss93mf3xKDQ2iAypUY12YNcQDrPpvWbVq8J6wPafJVq20KbR8X3WZU2wJ5LUZrptg45lOoTUe1oLdSY0IsOJutTbPaHD1KD6THlznAR4HASHA6kAblxlCrmaDyV/F1KVUNNGm5hbLXgwZNryCRxXoxz1jp5c+GZZzL6xcXSJEjdu4ocBXiA7TceHIq7ULW/E9o5Fwn01VzZGymVQXUTnAPjaQQQfIgWO474jcuPb7p30CmFO1qr7MY97HuizKtRnMBrrT0gdFaC6y7iCaFLTfBn9R6KMIpRV3sptR2Ce9pZ3lGpEltqjCJgwbOF9xldZVoUcS0Pw7w4im9oY69iZ8Tal2kHefyXDByIFZ6wtdfhBQwbXivihneQ4ta6MuS2VlNhJ1JniqG29sYauMwol7suVpcMsNkkniNTH2WABzTmNySFp3XNhA3AaDkExpFEasclG+r+9FfqIK+HDviHkg7hokjNOgl1gOPMcj+qlc8/uw9T+Sga4HQFx/D9yf0S69WbXtm7Wq0L03xv5A8Quj2H2/ql2WvNVswHhoBmJgEQ06j96cVUwpcCDABBBvJg+X5rnuzdVrO9DjPiDWgCZiRIHosZZS/LGpLH1JTcGiCozSJvC5XsFt2pi2vZVHipNb44jMDIAI421XW99Fo0Xlymrp0h3sAEjVNTObVCwEG8wiq3+H2UDVHZTAR5BE74nrqmpEAX15oIMzeJ6Qgdjsxgrx/+IGI7nGvplmVuRrmcC02+uZexVSCLa8l5n/GTZp7ujiMvwl1N3EB0FpJ1iWkdQtYX6lcA/bA0AJUTtqPO6B5ErLbSqxZpg3Doi39RspW4Sq43f6Eutw8IIXS0TVMc8iS+AdOfQXVY4kX8UngZur9Ds692jKh6BgnkTJ9lrYXsbVOlNo5nM4/WPZZ7QchVrz8LfX9Ehhqh+Ut5nwj1K9HodjXfNUM8Gw3/AKQFewvY2m0y5s8yp2NOC2PQrOhocI3kBrvcg+y1H7Ec743udyJJHpou7p7Aa34G+ii2xhTRpgtgOJgFwkCxNwp9yuj5I4mvsqlRbmdDeHPyG9Y1Tbz6Lw6gCyNXAAuI4ZTYjSxVja9GqHTVkk79QfI/ZZv+DzNe4kDKBAtLiXRAE7hJJ8l1nHpm5bHsXtDUplwJs973m0eJ5kmPsukw2IFXkd3Arha1KFqbF2jlIDjbceC1jdM2Op01RBT1DTyF1RmcOYWtAc5mV5iKktuYAMDSTKk2fsatVaHNaA0ixc7X0C69jHG3xXaQOfsoaWKD5IkQSDLXNiLfMPcK5idlYhh/0sw4tdI+ioNq3yuBa4loExlF/EXHXSBy+k3PS4WexK5/rz/JC6pxMe36q5S2ePmfPJogepv7Kwyixt2sA5nxH1Kzc2pgzabHO+FrjzjK3+4/mpW4J3zOa3k0SfU/qtajQfU+Fpdz3euiq1Knic2LtcWnzEExx1U7Vrpr6rDCsnSebjm9tPZZ3aPBVa1NtOk4N8XikkeGDaBzItyWlUqAXc4AczAWfU27QBytfndwYM3uLepWffUWHmG6aDfyCyziWt8LGxeIaI8tL+6tbTrVO5LhT+IsblN3EOcA6zdDBO8re7CuNKuHuDWnKZaIMA2EneefIq3wdZ/DDCVKWHe+owsdUf8AM2CWtmDBvFyu5FIG6p4HHtcLkTzUxad0rz27rSQ1A6w3oWjJrv4IjTy3G5M059d3BQM5ua490XeCMvT7IXPy2CLux8XX7oBa3Lc+yixuGbXaWuALd4cARxFlK1+axTuOTTfxQcuOxmGD8z2SfJaVHs1Qp3DG25LXbTDrnehFQusd6DOdstjvhaBHJJuBDbEei0nDJpv4pNZmuUGeNmfNaNfupf8ACNdYD1VrvD8O7T7J3Ny3Huggp4drNfZc526wD30mvpMLg1xLgNQIiY6LqmjPru4JjULbDcrLq7SzbxgEEQQHDeDp6bln4vYIdeiYP8h+xXpXbjYdIU++Y2KmYBxbaQZkkcZhcSxxGvqPvwXpxz252acPjsEWkhzSDwIWZUoFplegYraVJ9ZuFqszFzMzHf3SJ1BhsrN2r2acAXUv8xvD5h03q2b8NoOz2LNSmWH5INzxn8l6PsZ/+TTH4QvGGPqUy4NkTYjTT9la+D7VYukwMboBAkNJA6qb/t24spjfr1iq+xXmHaDaTaVYyCQDNtdyzsT2oxT9alVvHKWgewssypVc+QWueT8UyXHzM6aW5BMs5MbI1nnMm7X7ZsA8DCSeJj/lbx7WYWixhy96802ucflDiLtg6EHl1XnPdOFgA3y1RMwM3J9fsFzxyrOOWnWY/wDiNXf4aTQwbsok+pt7Lnam1K7pJqubJJJBkkk38z7Jm4cCwHT8/wAlr7K2A55zP0V+30yzt9ZeE2dUxDhOYji4kn3XRYnYrqVAih/rHKAbWEjMZPKVtUabaYytCgxeLDNbk6AanyH3T5GPQbSxpY0RqbfqVP2bpOJLjPii/l/yls7Y76xD6gsPhbuHnxK9B2FsMECRELnlntZB7EwrzB3c11lKqAIM2UFGiKdgFYFEG97rCgYSTfRFVt8Psnc8EQNUNMZdUBUgCL681HJmN09IRVG5jIRd4IjfEddECqAAW15JqV/i901NuUyUqgzaIGeSDbRSPaALRKZlQAQdQgZTIMnRA9K/xe6aoSDbTkiqHNpuTsdlEFA8CJtMdZQUySb6c02QzO6Z6ao3uzWCAatvh9kbGgi8ShpnLrvQvpkmRoUFTH4IV25HzBXA7a7O1sOZbNVnL4x/3dfVemPqAiBqUAYBOYWKstnhp8+47CuOOoVWN8EFrjBhrsr7OGrTpqujZWg8D9fLiu8252TZWPeUvA/iLeo3jkVxW0cC+ictZsD+YDwnz/l+nkuuObFxUsfs+jX+NuV+57Rf/dxXObS2JUo3IzM3PGnXgumII0uPfod6ko4gjTqDp1G5ddsz48/qU+ShqToLceJ6rtMXgKRblFOHl7nue2xc1xOWnl+ENaIAgbptJWng+yFECagJP9RP79FLNs8nLjhN5PMW4Z1/EIMT4QTYzZ2o6dVr/wCBf4ARBLAR4S0lpnKbgSDBuOq7HbWzWYakajA2RpLG/WJVSjixla+o4ABsybAWvroprScfPhyWzG+KmA2O1kFw6K5tLEClTLtDB7tsS57osAAs9u321GvNGHOa5oBdIaAQS55t8IgC+sqrhaFSs+Wuc5x+KqbEjhTHyN9ypcpEt5M8uuPyfu/5/q07GOgMaM1SBm4NMXzRvnd9FvbA7Olxz1PE86k/uw5LQ7N9nAyPCu7wGyA24C4W7elT2LsjLGYLoDTDQMtvJGXAiAmp+HVQFTAIvrzURceaJ7cxkKQVQLIA7vLeZhKc/KOqFjyTB0RVBl0sgWfLbX2S7r5p5x7p6bcwkoM5mN0x00QFnzW0SnJznonqNyiQmpjNqgXdZrzEpd5mtEShe8gwNApHsAEjUIBjJznolkzX0TUzm1ulUdlMDRA/efLHKfZLJlvqiyCJ3xPXVBTdmMFA8Z76R1S73LaJhNUOXRGxgIkoB7rLeZhKc/KELHkmDoUVQZdLIFny21UOKwDag8QBGsR1U9NuYSboM5mN0x00QcTtfsmQS7D2GpYdOn8p8vdcpXpFrsrgWvG469D8w/cL2So0NEhZO1tg0sU0h7b7iLEei1jnYlm3k73EPAtu+vBdRisY2m3M5wA5/bisvanZbFMeWtioBoXTMc4+L6qkexOLPiLabSNDkkj+4ldZyyPJz/xry2fdaY3aftMKzTSose+9yGkAR0lZW2dluqPa+tUa2m0Qxjb1DNyANJJ52XcYfsHiHfFWd0hv/SAr2G7AhjpcS48XGT6lYy5LXXg/jYcMsn7cTsnZBqQ3Jkpg2YOP8zj8zuZXo2wezmQAwtrZnZprBMaCVv4WmNDoubuhweBEcIVvvMto0SqHLpZExgIk6oB7vLeZhKc/KOqZjyTB0RVPDpaUDZ8ttUu5m8630T02hwk6oDVItKCWsLFR4fekkgavr0UseHp9kkkEVDVPidQkkgloiwVeibhJJBJidyKgLJ0kEA+Lr91NX06pJIGw+hUVXUpJIJ6wsVHh96SSBq+vRTR4en2TJIIsPr0RYjUJJIJKTRAVeiLhMkglxLRZFh22TpIIR8XX7qXEC3VOkgHDaFR1dSmSQWKwsVHht6SSAa+qsMFh5JJIP//Z'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터만의 미분 방식\n",
    "\n",
    " - 후진 방식: 이 중 하나가 back propagation이다. \n",
    " - 전진 방식\n",
    " \n",
    "ndarray로 미분값 계산하는게 바로 후진방식 자동미분이다. 백프로파게이션처럼 뒤에서 계산해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2, 2))\n",
    "\n",
    "# with는 context mamager라고도 한다.\n",
    "# loss function을 넣어줘야 한다. with 안에\n",
    "# with 벗어나도 값 안없어진다.\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x) # x를 변수처럼 여긴다. 이걸 안하면 결과값이 None이 된다.\n",
    "    y = tf.reduce_sum(x) # loss function\n",
    "    z = tf.multiply(y, y)# 최종 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def __exit__(self, exc_type, exc_value, exc_tb):\n",
      "        self.__fallback()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(plt.xkcd().__exit__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fallback은 앞부분 실행되기 이전 상태로 돌아가라는 뜻이다. 항상 close가 아니다. 항상 with 구문이 나오면, close인지 아닌지 inspect로 알아봐야 한다.\n",
    "\n",
    "gradient tape에 로스 펑션을 집어넣는게 핵심이다. ★★★"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 입력 텐서 x에 대한 z의 도함수\n",
    "dz_dx = t.gradient(z, x) # z함수를 x에 관해서 미분해라라는 뜻\n",
    "# 각각이 다 0이 안나왔는지 확인하는 구문. 결국엔 8.0인지를 체크한다.\n",
    "for i in [0, 1]:\n",
    "    for j in [0, 1]:\n",
    "        assert dz_dx[i][j].numpy() == 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 tf.GradientTape 컨텍스트 안에서 계산된 중간값에 대한 그래디언트도 구할 수 있습니다. (eager tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 없이 gradient tape 돌리는 실험.\n",
    "x = tf.Variable((2, 2)) # 상수가 아니면 될까? -> 안됨.\n",
    "t = tf.GradientTape()\n",
    "# t.watch(x)\n",
    "y = tf.reduce_sum(x)\n",
    "z = tf.multiply(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9fc5b10137c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdz_dx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \"\"\"\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[0;32m    966\u001b[0m                          \"non-persistent tapes.\")\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "dz_dx = t.gradient(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: GradientTape.gradient can only be called once on non-persistent tapes.\n",
    "\n",
    "이런 에러가 나온다. 이젠 persist를 true로 줘버리자. 그레디언트 테입 인스턴스 선언 옵션으로."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_tape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e92bce0920a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 상수가 아니면 될까? -> 안됨.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;31m# `handle` attribute that points to a tensor. If this changes, internals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;31m# of watch_variable need to change as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\tape.py\u001b[0m in \u001b[0;36mwatch_variable\u001b[1;34m(tape, variable)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_local_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_Py_TapeWatchVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_tape'"
     ]
    }
   ],
   "source": [
    "# with 없이 gradient tape 돌리는 실험.\n",
    "x = tf.Variable((2, 2)) # 상수가 아니면 될까? -> 안됨.\n",
    "t = tf.GradientTape(persistent=True)\n",
    "t.watch(x)\n",
    "y = tf.reduce_sum(x)\n",
    "z = tf.multiply(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9fc5b10137c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdz_dx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \"\"\"\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[0;32m    966\u001b[0m                          \"non-persistent tapes.\")\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "dz_dx = t.gradient(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래도 안된다. 이제 이걸 검사해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def __enter__(self):\n",
      "    \"\"\"Enters a context inside which operations are recorded on this tape.\"\"\"\n",
      "    self._push_tape()\n",
      "    return self\n",
      "\n",
      "  def __exit__(self, typ, value, traceback):\n",
      "    \"\"\"Exits the recording context, no further operations are traced.\"\"\"\n",
      "    if self._recording:\n",
      "      self._pop_tape()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(tf.GradientTape().__enter__))\n",
    "print(inspect.getsource(tf.GradientTape().__exit__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push와 pop이라는게 나오는데, 이는 그레디언트 테입에 넣어야지만 계산이 된다는 뜻이다.\n",
    "\n",
    "persist 옵션은 더이상 메모리에서 쓰지 않는 것들을 없애줄지 유지해줄지 옵션이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getrefcount(x) # gradient tape에 있는 것들은 기록이 유지되지 않는다.\n",
    "# 더이상 사용되지 않는 것은 알아서 없애주는 기능 (가비지 컬렉션이라고 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(108.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "    t.watch(x)\n",
    "    y = x * x # 이 중간값까지 확인하려면, persistent = True로 해주면 된다.\n",
    "    z = y * y # 결국 z는 x의 4제곱이다.\n",
    "print(t.gradient(z, x))  # 108.0 (4*x^3 at x = 3)\n",
    "print(t.gradient(y, x))  # 6.0\n",
    "del t  # 테이프에 대한 참조를 삭제합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persist 한것에 따라서, y값 같은 중간 값들을 쓸 수 있는지 없는지가 정해진다. 이건 홈페이지 설명봐도 모르니, 잘 공부해둘 것. ★★★ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제어 흐름 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def f(x, y):\n",
    "    output = 1.0\n",
    "    # 조건에 따라서 다른 grad를 적용할 수 있음\n",
    "    for i in range(y):\n",
    "        if i > 1 and i < 5:\n",
    "            output = tf.multiply(output, x)\n",
    "    return output\n",
    "\n",
    "# 미분한 값을 도출해주는 함수\n",
    "def grad(x, y):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(x)\n",
    "        out = f(x, y)\n",
    "    return t.gradient(out, x)\n",
    "\n",
    "x = tf.convert_to_tensor(2.0)\n",
    "\n",
    "assert grad(x, 6).numpy() == 12.0 # 5 계산한 결과와 똑같다. \n",
    "assert grad(x, 5).numpy() == 12.0\n",
    "assert grad(x, 4).numpy() == 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고계도 그래디언트\n",
    "\n",
    "with 안에 또 wit를 이런식으로 쓸 수 있다. 미분을 한 번 하면, 기울기 함수이고, 여기서 한 번 더 미분하면 고계도 함수가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0)  # 1.0으로 초기화된 텐서플로 변수를 생성합니다.\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x * x\n",
    "  # 't' 컨텍스트 매니저 안의 그래디언트를 계산합니다.\n",
    "  # 이것은 또한 그래디언트 연산 자체도 미분가능하다는 것을 의미합니다. \n",
    "    dy_dx = t2.gradient(y, x)\n",
    "d2y_dx2 = t.gradient(dy_dx, x)\n",
    "\n",
    "assert dy_dx.numpy() == 3.0\n",
    "assert d2y_dx2.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/customization/custom_training\n",
    "\n",
    "# 사용자 정의 학습: 기초\n",
    "\n",
    "\n",
    "### 변수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 구문 사용\n",
    "x = tf.zeros([10, 10])\n",
    "x += 2  # 이것은 x = x + 2와 같으며, x의 초기값을 변경하지 않습니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(1.0)\n",
    "assert v.numpy() == 1.0\n",
    "\n",
    "# 값을 재배열합니다.\n",
    "v.assign(3.0)\n",
    "assert v.numpy() == 3.0\n",
    "\n",
    "# tf.square()와 같은 텐서플로 연산에 `v`를 사용하고 재할당합니다. \n",
    "v.assign(tf.square(v))\n",
    "assert v.numpy() == 9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.resource_variable_ops.ResourceVariable"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.Variable([1, 1, 1])) # eager tensor가 아니다.\n",
    "                             # 값이 미리 안나올 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        # 변수를 (5.0, 0.0)으로 초기화 합니다.\n",
    "        # 실제로는 임의의 값으로 초기화 되어야합니다.\n",
    "        self.W = tf.Variable(5.0)\n",
    "        self.b = tf.Variable(0.0)\n",
    "\n",
    "    def __call__(self, x): # 이렇게 해두면, 인스턴스에서 괄호를 사용가능\n",
    "        return self.W * x + self.b\n",
    "\n",
    "model = Model() \n",
    "\n",
    "assert model(3.0).numpy() == 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE 함수이다.\n",
    "def loss(predicted_y, desired_y):\n",
    "    return tf.reduce_mean(tf.square(predicted_y - desired_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 fit을 사용할 수 없다. 정의가 안되있기 때문. 그래서 우리가 직접 loss function을 최소화하는 애를 만들것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_W = 3.0\n",
    "TRUE_b = 2.0\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "inputs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "noise   = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "outputs = inputs * TRUE_W + TRUE_b + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(model(inputs), outputs)\n",
    "    dW, db = t.gradient(current_loss, [model.W, model.b])\n",
    "    model.W.assign_sub(learning_rate * dW) # -=와 같은 개념이다. 기존에서 계속 뺌.\n",
    "    model.b.assign_sub(learning_rate * db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크  0: W=5.00 b=0.00, 손실=9.05823\n",
      "에포크  1: W=4.61 b=0.41, 손실=6.16718\n",
      "에포크  2: W=4.29 b=0.73, 손실=4.31228\n",
      "에포크  3: W=4.04 b=0.99, 손실=3.12212\n",
      "에포크  4: W=3.83 b=1.20, 손실=2.35844\n",
      "에포크  5: W=3.67 b=1.37, 손실=1.86838\n",
      "에포크  6: W=3.54 b=1.50, 손실=1.55390\n",
      "에포크  7: W=3.43 b=1.61, 손실=1.35208\n",
      "에포크  8: W=3.35 b=1.69, 손실=1.22255\n",
      "에포크  9: W=3.28 b=1.76, 손실=1.13941\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# 도식화를 위해 W값과 b값의 변화를 저장합니다.\n",
    "Ws, bs = [], []\n",
    "epochs = range(10)\n",
    "for epoch in epochs: # 이렇게 그냥 써도 상관 없다.\n",
    "    Ws.append(model.W.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "    current_loss = loss(model(inputs), outputs)\n",
    "    \n",
    "    train(model, inputs, outputs, learning_rate=0.1) # 에폭에 조건 걸어서 러닝레이트를 조절할 수 있다.\n",
    "    print('에포크 %2d: W=%1.2f b=%1.2f, 손실=%2.5f' %\n",
    "        (epoch, Ws[-1], bs[-1], current_loss))\n",
    "\n",
    "# 저장된 값들을 도식화합니다.\n",
    "plt.plot(epochs, Ws, 'r',\n",
    "         epochs, bs, 'b')\n",
    "plt.plot([TRUE_W] * len(epochs), 'r--',\n",
    "         [TRUE_b] * len(epochs), 'b--')\n",
    "plt.legend(['W', 'b', 'true W', 'true_b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 gradient tape를 쓰면 fit보다 훨씬 우아하게 코딩을 할 수 있다.\n",
    "\n",
    "https://modelzoo.co/framework/tensorflow : 모델 코드 좋은거 많다. 그런데 거의다 1.0 버전이다.\n",
    "\n",
    "그럼 1.0의 코드를 2.0으로 바꿀 수 없을까? -> 텐서플로에 다 있다. guide 들어가면 시간될 때 공부할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로2.0 최적화가 안되어 있다. 1.0에 비해서... 그럼 이결 해결하는 방법은? 데코레이터 쓰면 된다. ★★★\n",
    "\n",
    "https://www.tensorflow.org/tutorials/customization/performance\n",
    "\n",
    "# Better performance with tf.function\n",
    "\n",
    " - 넘파이보다는 tensor를 써야 최적의 성능이 나온다.\n",
    " - 넘파이로 만들었다면, 오히려 데코레이터 붙였다가 손해만 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=374, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function # 성능향상이 있다.\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 텐서로 바꾸는지 이제 알거다. 속도 더 빠른 이유가 이 데코레이터를 써서 그렇다. gpu 써서 빠른것도 있지만, 이것도 엄청 크다. 여기서는 그냥 이정도만 살펴보고 넘어가보자.\n",
    "\n",
    "그냥 fit 시키는건 왜 하나? 어떤 장점이 있는가... \n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "fit 시킬 때, 뭘 할 수 있냐면 콜백을 할 수 있다. 콜백은 콜을 하고 그 결과로 실행되는 함수를 말한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-197fbacc2ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 함수에서 콜백이 있는데, 이건 1에폭 돌때마다 나오는 함수를 말한다. 어떤 함수를 실행된 결과로 나오는 것이다. 선생님은 이거 설정 잘해놔서 1에폭 돌때마다, 텔레그램으로 메시지 오게 설정해뒀다고 함 ㅋㅋㅋ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로 2.0 시작하기: 초보자용 콜백실습\n",
    "\n",
    "fit 함수에 가서 콜백을 추가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "콜백은 어떤 애를 상속받아서 넣어야 한다. 아래처럼.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    pass\n",
    "\n",
    "my = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, callbacks = [my, es]) # 이런식으로 쓴다.\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'set_model',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "on_train_begin() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7619b40bd12c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: on_train_begin() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "Callback.on_train_begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "시작\n",
      "에폭 0 시작\n",
      "Epoch 1/3\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9921에폭 끝 {'loss': 0.022998865557937096, 'accuracy': 0.9921333}\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0230 - accuracy: 0.9921\n",
      "에폭 1 시작\n",
      "Epoch 2/3\n",
      "59328/60000 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9929에폭 끝 {'loss': 0.019505027878868715, 'accuracy': 0.9929}\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0195 - accuracy: 0.9929\n",
      "에폭 2 시작\n",
      "Epoch 3/3\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9923에폭 끝 {'loss': 0.021424682563073536, 'accuracy': 0.9923}\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0214 - accuracy: 0.9923\n",
      "끝\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b86da3948>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCallback(Callback):\n",
    "    def on_train_begin(self, logs): # 오버라이딩 기법: 학습 시작전에 실행\n",
    "        print('시작')\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self, logs): # 오버라이딩 기법: 학습이 끝난 후 실행\n",
    "        print('끝')\n",
    "        \n",
    "    def on_epoch_begin(self, epochs, logs): # 1에폭 돌기 전에 실행\n",
    "        if epoch == 1:\n",
    "            print('에폭 시작', logs)\n",
    "        else:\n",
    "            print('에폭', epochs, '시작')\n",
    "        \n",
    "    def on_epoch_end(self, epochs, logs): # 1에폭 돌고나서 실행\n",
    "        print('에폭 끝', logs)\n",
    "        \n",
    "    \n",
    "        \n",
    "my = MyCallback()\n",
    "model.fit(x_train, y_train, epochs=3, callbacks = [my]) # s가 있으니, 다양한 것들을 많이 넣을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard # 이렇게 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(EarlyStopping)\n",
    "issubclass(EarlyStopping, Callback) # 얘도 callbacks의 상속이다.\n",
    "\n",
    "es = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def on_epoch_end(self, epoch, logs=None):\n",
      "    current = self.get_monitor_value(logs)\n",
      "    if current is None:\n",
      "      return\n",
      "    if self.monitor_op(current - self.min_delta, self.best):\n",
      "      self.best = current\n",
      "      self.wait = 0\n",
      "      if self.restore_best_weights:\n",
      "        self.best_weights = self.model.get_weights()\n",
      "    else:\n",
      "      self.wait += 1\n",
      "      if self.wait >= self.patience:\n",
      "        self.stopped_epoch = epoch\n",
      "        self.model.stop_training = True\n",
      "        if self.restore_best_weights:\n",
      "          if self.verbose > 0:\n",
      "            print('Restoring model weights from the end of the best epoch.')\n",
      "          self.model.set_weights(self.best_weights)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getsource(EarlyStopping.on_epoch_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9933WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 2/3\n",
      "59360/60000 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9927WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 3/3\n",
      "59584/60000 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9931WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0192 - accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26babc1a648>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCallback(Callback):\n",
    "    def on_train_begin(self, logs): # 오버라이딩 기법: 학습 시작전에 실행\n",
    "        print('시작')\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self, logs): # 오버라이딩 기법: 학습이 끝난 후 실행\n",
    "        print('끝')\n",
    "        \n",
    "    def on_epoch_begin(self, epochs, logs): # 1에폭 돌기 전에 실행\n",
    "        if epoch == 1:\n",
    "            print('에폭 시작', logs)\n",
    "        else:\n",
    "            print('에폭', epochs, '시작')\n",
    "        \n",
    "    def on_epoch_end(self, epochs, logs): # 1에폭 돌고나서 실행\n",
    "        print('에폭 끝', logs)\n",
    "        \n",
    "    \n",
    "        \n",
    "my = MyCallback()\n",
    "model.fit(x_train, y_train, epochs=3, callbacks = [es]) # s가 있으니, 다양한 것들을 많이 넣을 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 콜백으로 뭘 할 수 있냐면, 모델을 저장할 수 있다.\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load : 체크포인트 콜백 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0197 - accuracy: 0.9933\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.0202 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26ba6dd9708>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "cl = CSVLogger('csv_logger_log.csv')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3, callbacks = [cl])\n",
    "# 파일을 csv로 저장해둘 수 있다. 메일로 보내주는 기능도 추가할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2.0-GPU",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
